<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8164484c16b1ed3287ef9dae9fc437c1",
  "translation_date": "2025-07-24T07:37:38+00:00",
  "source_file": "10-ai-agents-production/README.md",
  "language_code": "ru"
}
-->
# AI-агенты в производстве: наблюдаемость и оценка

Когда AI-агенты переходят от экспериментальных прототипов к реальным приложениям, способность понимать их поведение, отслеживать их производительность и систематически оценивать их результаты становится крайне важной.

## Цели обучения

После завершения этого урока вы узнаете/поймете:
- Основные концепции наблюдаемости и оценки агентов
- Техники улучшения производительности, затрат и эффективности агентов
- Что и как систематически оценивать в ваших AI-агентах
- Как контролировать затраты при развертывании AI-агентов в производстве
- Как инструментировать агентов, созданных с помощью AutoGen

Цель — дать вам знания, чтобы превратить ваших "черных ящиков" в прозрачные, управляемые и надежные системы.

_**Примечание:** Важно развертывать AI-агентов, которые безопасны и заслуживают доверия. Ознакомьтесь с уроком [Создание надежных AI-агентов](./06-building-trustworthy-agents/README.md)._

## Трейсы и спаны

Инструменты наблюдаемости, такие как [Langfuse](https://langfuse.com/) или [Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry), обычно представляют выполнение задач агентами в виде трейсов и спанов.

- **Трейс** представляет собой полную задачу агента от начала до конца (например, обработка пользовательского запроса).
- **Спаны** — это отдельные шаги внутри трейса (например, вызов языковой модели или извлечение данных).

![Дерево трейсов в Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

Без наблюдаемости AI-агент может казаться "черным ящиком" — его внутреннее состояние и логика остаются непрозрачными, что затрудняет диагностику проблем или оптимизацию производительности. С наблюдаемостью агенты превращаются в "стеклянные ящики", обеспечивая прозрачность, которая жизненно важна для построения доверия и гарантии их корректной работы.

## Почему наблюдаемость важна в производственных средах

Переход AI-агентов в производственные среды влечет за собой новые вызовы и требования. Наблюдаемость становится не просто "желательной", а критически важной способностью:

*   **Отладка и анализ причин ошибок**: Когда агент терпит неудачу или выдает неожиданный результат, инструменты наблюдаемости предоставляют трейсы, необходимые для выявления источника ошибки. Это особенно важно для сложных агентов, которые могут включать множество вызовов LLM, взаимодействий с инструментами и условной логики.
*   **Управление задержками и затратами**: AI-агенты часто зависят от LLM и других внешних API, которые оплачиваются за токен или вызов. Наблюдаемость позволяет точно отслеживать эти вызовы, помогая выявлять операции, которые слишком медленные или дорогие. Это позволяет командам оптимизировать подсказки, выбирать более эффективные модели или перерабатывать рабочие процессы для управления эксплуатационными расходами и обеспечения хорошего пользовательского опыта.
*   **Доверие, безопасность и соответствие требованиям**: Во многих приложениях важно гарантировать, что агенты ведут себя безопасно и этично. Наблюдаемость предоставляет журнал действий и решений агента. Это можно использовать для выявления и устранения таких проблем, как инъекция подсказок, генерация вредоносного контента или неправильное обращение с персональными данными (PII). Например, вы можете просмотреть трейсы, чтобы понять, почему агент дал определенный ответ или использовал конкретный инструмент.
*   **Циклы непрерывного улучшения**: Данные наблюдаемости являются основой итеративного процесса разработки. Наблюдая за тем, как агенты работают в реальном мире, команды могут выявлять области для улучшения, собирать данные для дообучения моделей и проверять влияние изменений. Это создает цикл обратной связи, где производственные инсайты из онлайн-оценки информируют оффлайн-эксперименты и доработки, что приводит к постепенному улучшению производительности агентов.

## Ключевые метрики для отслеживания

Для мониторинга и понимания поведения агентов необходимо отслеживать ряд метрик и сигналов. Хотя конкретные метрики могут варьироваться в зависимости от назначения агента, некоторые из них являются универсально важными.

Вот некоторые из наиболее распространенных метрик, которые отслеживают инструменты наблюдаемости:

**Задержка:** Как быстро агент отвечает? Долгое ожидание негативно сказывается на пользовательском опыте. Вы должны измерять задержку для задач и отдельных шагов, отслеживая выполнение агентов. Например, агент, который тратит 20 секунд на все вызовы модели, может быть ускорен за счет использования более быстрой модели или параллельного выполнения вызовов.

**Затраты:** Какова стоимость выполнения задачи агентом? AI-агенты зависят от вызовов LLM, оплачиваемых за токен, или внешних API. Частое использование инструментов или множество подсказок могут быстро увеличить затраты. Например, если агент вызывает LLM пять раз для незначительного улучшения качества, необходимо оценить, оправданы ли затраты, или можно сократить количество вызовов или использовать более дешевую модель. Мониторинг в реальном времени также помогает выявлять неожиданные всплески (например, ошибки, вызывающие избыточные циклы API).

**Ошибки запросов:** Сколько запросов агента завершились неудачей? Это может включать ошибки API или неудачные вызовы инструментов. Чтобы сделать вашего агента более устойчивым к этим проблемам в производстве, вы можете настроить резервные механизмы или повторные попытки. Например, если провайдер LLM A недоступен, вы переключаетесь на провайдера LLM B в качестве резервного.

**Обратная связь от пользователей:** Реализация прямой оценки пользователями предоставляет ценные инсайты. Это может включать явные оценки (👍пальцы вверх/👎вниз, ⭐1-5 звезд) или текстовые комментарии. Постоянно негативная обратная связь должна вас насторожить, так как это признак того, что агент работает не так, как ожидалось.

**Неявная обратная связь от пользователей:** Поведение пользователей предоставляет косвенную обратную связь даже без явных оценок. Это может включать немедленное перефразирование вопросов, повторные запросы или нажатие кнопки повторного выполнения. Например, если вы видите, что пользователи неоднократно задают один и тот же вопрос, это признак того, что агент работает не так, как ожидалось.

**Точность:** Как часто агент выдает правильные или желаемые результаты? Определения точности могут варьироваться (например, правильность решения задач, точность извлечения информации, удовлетворенность пользователей). Первый шаг — определить, что означает успех для вашего агента. Вы можете отслеживать точность с помощью автоматических проверок, оценочных баллов или меток завершения задач. Например, помечая трейсы как "успешные" или "неудачные".

**Автоматические метрики оценки:** Вы также можете настроить автоматические оценки. Например, вы можете использовать LLM для оценки результата агента, например, насколько он полезен, точен или нет. Существуют также несколько библиотек с открытым исходным кодом, которые помогают оценивать различные аспекты агента. Например, [RAGAS](https://docs.ragas.io/) для агентов RAG или [LLM Guard](https://llm-guard.com/) для обнаружения вредоносного языка или инъекций подсказок.

На практике комбинация этих метрик обеспечивает наилучшее покрытие состояния AI-агента. В [примерной тетрадке](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) этой главы мы покажем, как эти метрики выглядят на реальных примерах, но сначала мы изучим, как выглядит типичный рабочий процесс оценки.

## Инструментирование вашего агента

Чтобы собирать данные о трейсах, вам нужно инструментировать ваш код. Цель — настроить код агента так, чтобы он генерировал трейсы и метрики, которые могут быть захвачены, обработаны и визуализированы платформой наблюдаемости.

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) стал отраслевым стандартом для наблюдаемости LLM. Он предоставляет набор API, SDK и инструментов для генерации, сбора и экспорта телеметрических данных.

Существует множество библиотек инструментирования, которые оборачивают существующие фреймворки агентов и упрощают экспорт спанов OpenTelemetry в инструмент наблюдаемости. Ниже приведен пример инструментирования агента AutoGen с помощью библиотеки инструментирования [OpenLit](https://github.com/openlit/openlit):

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

[Примерная тетрадка](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) в этой главе продемонстрирует, как инструментировать вашего агента AutoGen.

**Ручное создание спанов:** Хотя библиотеки инструментирования предоставляют хорошую базу, часто возникают случаи, когда требуется более детальная или кастомная информация. Вы можете вручную создавать спаны, чтобы добавить пользовательскую логику приложения. Более того, вы можете обогащать автоматически или вручную созданные спаны пользовательскими атрибутами (также известными как теги или метаданные). Эти атрибуты могут включать бизнес-специфичные данные, промежуточные вычисления или любой контекст, который может быть полезен для отладки или анализа, например, `user_id`, `session_id` или `model_version`.

Пример создания трейсов и спанов вручную с помощью [Langfuse Python SDK](https://langfuse.com/docs/sdk/python/sdk-v3):

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## Оценка агентов

Наблюдаемость предоставляет нам метрики, но оценка — это процесс анализа этих данных (и проведения тестов) для определения того, насколько хорошо работает AI-агент и как его можно улучшить. Иными словами, как только у вас есть трейсы и метрики, как вы используете их для оценки агента и принятия решений?

Регулярная оценка важна, потому что AI-агенты часто являются недетерминированными и могут эволюционировать (через обновления или дрейф поведения модели) — без оценки вы не узнаете, выполняет ли ваш "умный агент" свою работу хорошо или регрессирует.

Существует две категории оценки AI-агентов: **оффлайн-оценка** и **онлайн-оценка**. Обе они ценны и дополняют друг друга. Обычно мы начинаем с оффлайн-оценки, так как это минимально необходимый шаг перед развертыванием любого агента.

### Оффлайн-оценка

![Элементы набора данных в Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

Этот процесс включает оценку агента в контролируемой среде, обычно с использованием тестовых наборов данных, а не живых пользовательских запросов. Вы используете подготовленные наборы данных, где вы знаете ожидаемый результат или правильное поведение, и затем запускаете агента на них.

Например, если вы создали агента для решения математических задач, у вас может быть [тестовый набор данных](https://huggingface.co/datasets/gsm8k) из 100 задач с известными ответами. Оффлайн-оценка часто проводится во время разработки (и может быть частью CI/CD-пайплайнов) для проверки улучшений или предотвращения регрессий. Преимущество в том, что это **повторяемо, и вы можете получить четкие метрики точности, так как у вас есть эталонные данные**. Вы также можете симулировать пользовательские запросы и измерять ответы агента относительно идеальных ответов или использовать автоматические метрики, описанные выше.

Ключевая сложность оффлайн-оценки заключается в обеспечении того, чтобы ваш тестовый набор данных был всеобъемлющим и оставался актуальным — агент может хорошо работать на фиксированном тестовом наборе, но сталкиваться с совершенно другими запросами в производстве. Поэтому вы должны регулярно обновлять тестовые наборы новыми крайними случаями и примерами, отражающими реальные сценарии. Полезно иметь смесь небольших "дымовых тестов" и более крупных наборов для оценки: небольшие наборы для быстрых проверок и более крупные для более широких метрик производительности.

### Онлайн-оценка

![Обзор метрик наблюдаемости](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

Этот процесс включает оценку агента в живой, реальной среде, то есть во время фактического использования в производстве. Онлайн-оценка включает мониторинг производительности агента на реальных взаимодействиях с пользователями и непрерывный анализ результатов.

Например, вы можете отслеживать показатели успешности, оценки удовлетворенности пользователей или другие метрики на живом трафике. Преимущество онлайн-оценки в том, что она **позволяет выявить то, что вы могли не предусмотреть в лабораторных условиях** — вы можете наблюдать дрейф модели со временем (если эффективность агента ухудшается по мере изменения входных данных) и фиксировать неожиданные запросы или ситуации, которых не было в ваших тестовых данных. Это дает реальную картину того, как агент ведет себя в реальных условиях.

Онлайн-оценка часто включает сбор неявной и явной обратной связи от пользователей, как обсуждалось ранее, а также, возможно, проведение теневых тестов или A/B-тестов (где новая версия агента работает параллельно для сравнения со старой). Сложность заключается в том, что может быть трудно получить надежные метки или оценки для живых взаимодействий — вы можете полагаться на обратную связь пользователей или метрики downstream (например, кликнул ли пользователь на результат).

### Комбинирование двух подходов

Онлайн- и оффлайн-оценки не являются взаимоисключающими; они прекрасно дополняют друг друга. Инсайты из онлайн-мониторинга (например, новые типы пользовательских запросов, где агент работает плохо) могут быть использованы для дополнения и улучшения оффлайн-тестовых наборов данных. С другой стороны, агенты, которые хорошо работают в оффлайн-тестах, могут быть с большей уверенностью развернуты и мониториться онлайн.

Фактически, многие команды используют следующий цикл:

_оценка оффлайн -> развертывание -> мониторинг онлайн -> сбор новых случаев сбоев -> добавление в оффлайн-набор данных -> доработка агента -> повторение_.

## Распространенные проблемы

При развертывании AI-агентов в производстве вы можете столкнуться с различными вызовами. Вот некоторые распространенные проблемы и возможные решения:

| **Проблема**    | **Возможное решение**   |
| ------------- | ------------------ |
| Агент AI выполняет задачи непоследовательно | - Уточните подсказку, предоставляемую агенту AI; четко определите цели.<br>- Определите, где разделение задач на подзадачи и их выполнение несколькими агентами может помочь. |
| Агент AI застревает в бесконечных циклах  | - Убедитесь, что у вас есть четкие условия завершения, чтобы агент знал, когда остановить процесс.<br>- Для сложных задач, требующих рассуждений и планирования, используйте более крупную модель, специализированную для таких задач. |
| Вызовы инструментов агента AI работают некорректно   | - Протестируйте и проверьте вывод инструмента вне системы агента. |

- Уточните заданные параметры, подсказки и названия инструментов.  
| Многоагентная система работает нестабильно | - Уточните подсказки, предоставляемые каждому агенту, чтобы они были конкретными и отличались друг от друга.<br>- Постройте иерархическую систему, используя "маршрутизирующего" или управляющего агента, чтобы определить, какой агент является подходящим. |

Многие из этих проблем можно выявить гораздо эффективнее, если внедрить инструменты наблюдаемости. Трассировки и метрики, которые мы обсуждали ранее, помогают точно определить, на каком этапе рабочего процесса агента возникают проблемы, что делает отладку и оптимизацию гораздо более эффективными.

## Управление затратами

Вот несколько стратегий для управления затратами при развертывании ИИ-агентов в продакшене:

**Использование меньших моделей:** Малые языковые модели (SLM) могут хорошо справляться с определенными агентными задачами и значительно снизят затраты. Как упоминалось ранее, создание системы оценки для определения и сравнения производительности с более крупными моделями — лучший способ понять, насколько хорошо SLM справится с вашей задачей. Рассмотрите возможность использования SLM для более простых задач, таких как классификация намерений или извлечение параметров, оставляя более крупные модели для сложных рассуждений.

**Использование маршрутизирующей модели:** Похожая стратегия заключается в использовании разнообразных моделей разного размера. Вы можете использовать LLM/SLM или серверлесс-функцию для маршрутизации запросов в зависимости от их сложности к наиболее подходящим моделям. Это также поможет сократить затраты, обеспечивая при этом производительность для нужных задач. Например, направляйте простые запросы к меньшим, более быстрым моделям, а дорогие крупные модели используйте только для сложных задач рассуждения.

**Кэширование ответов:** Определение общих запросов и задач и предоставление ответов до того, как они пройдут через вашу агентную систему, — это хороший способ сократить объем похожих запросов. Вы даже можете реализовать процесс для определения степени схожести запроса с уже закэшированными запросами, используя более базовые модели ИИ. Эта стратегия может значительно сократить затраты на часто задаваемые вопросы или типовые рабочие процессы.

## Давайте посмотрим, как это работает на практике

В [примере ноутбука из этого раздела](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) мы увидим примеры того, как можно использовать инструменты наблюдаемости для мониторинга и оценки работы агента.

## Предыдущий урок

[Шаблон проектирования метакогниции](../09-metacognition/README.md)

## Следующий урок

[MCP](../11-mcp/README.md)

**Отказ от ответственности**:  
Этот документ был переведен с использованием сервиса автоматического перевода [Co-op Translator](https://github.com/Azure/co-op-translator). Хотя мы стремимся к точности, пожалуйста, учитывайте, что автоматические переводы могут содержать ошибки или неточности. Оригинальный документ на его родном языке следует считать авторитетным источником. Для получения критически важной информации рекомендуется профессиональный перевод человеком. Мы не несем ответственности за любые недоразумения или неправильные интерпретации, возникшие в результате использования данного перевода.