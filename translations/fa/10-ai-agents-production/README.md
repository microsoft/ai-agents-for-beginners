<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8164484c16b1ed3287ef9dae9fc437c1",
  "translation_date": "2025-07-24T07:42:05+00:00",
  "source_file": "10-ai-agents-production/README.md",
  "language_code": "fa"
}
-->
# عوامل هوش مصنوعی در تولید: مشاهده‌پذیری و ارزیابی

با حرکت عوامل هوش مصنوعی از نمونه‌های اولیه آزمایشی به برنامه‌های واقعی، توانایی درک رفتار آن‌ها، نظارت بر عملکردشان و ارزیابی سیستماتیک خروجی‌هایشان اهمیت پیدا می‌کند.

## اهداف یادگیری

پس از تکمیل این درس، شما خواهید دانست که چگونه/چه چیزی را:
- مفاهیم اصلی مشاهده‌پذیری و ارزیابی عوامل
- تکنیک‌های بهبود عملکرد، هزینه‌ها و اثربخشی عوامل
- ارزیابی سیستماتیک عوامل هوش مصنوعی خود
- کنترل هزینه‌ها هنگام استقرار عوامل هوش مصنوعی در تولید
- ابزارسازی عوامل ساخته‌شده با AutoGen

هدف این است که شما را با دانش لازم برای تبدیل عوامل "جعبه سیاه" به سیستم‌های شفاف، قابل مدیریت و قابل اعتماد مجهز کنیم.

_**توجه:** استقرار عوامل هوش مصنوعی ایمن و قابل اعتماد بسیار مهم است. درس [ساخت عوامل هوش مصنوعی قابل اعتماد](./06-building-trustworthy-agents/README.md) را نیز بررسی کنید._

## ردیابی‌ها و بخش‌ها

ابزارهای مشاهده‌پذیری مانند [Langfuse](https://langfuse.com/) یا [Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry) معمولاً اجرای عوامل را به‌صورت ردیابی‌ها و بخش‌ها نمایش می‌دهند.

- **ردیابی (Trace):** نمایانگر یک وظیفه کامل عامل از ابتدا تا انتها است (مانند پاسخ به یک پرسش کاربر).
- **بخش‌ها (Spans):** مراحل جداگانه درون ردیابی هستند (مانند فراخوانی یک مدل زبانی یا بازیابی داده‌ها).

![درخت ردیابی در Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

بدون مشاهده‌پذیری، یک عامل هوش مصنوعی می‌تواند مانند یک "جعبه سیاه" به نظر برسد - حالت داخلی و استدلال آن مبهم است و تشخیص مشکلات یا بهینه‌سازی عملکرد دشوار می‌شود. با مشاهده‌پذیری، عوامل به "جعبه‌های شیشه‌ای" تبدیل می‌شوند که شفافیتی حیاتی برای ایجاد اعتماد و اطمینان از عملکرد صحیح آن‌ها فراهم می‌کند.

## چرا مشاهده‌پذیری در محیط‌های تولید اهمیت دارد؟

انتقال عوامل هوش مصنوعی به محیط‌های تولید چالش‌ها و نیازمندی‌های جدیدی را معرفی می‌کند. مشاهده‌پذیری دیگر یک قابلیت "خوب است که داشته باشیم" نیست، بلکه یک قابلیت حیاتی است:

*   **اشکال‌زدایی و تحلیل علت ریشه‌ای:** وقتی یک عامل شکست می‌خورد یا خروجی غیرمنتظره‌ای تولید می‌کند، ابزارهای مشاهده‌پذیری ردیابی‌های لازم برای شناسایی منبع خطا را فراهم می‌کنند. این امر به‌ویژه در عوامل پیچیده که ممکن است شامل چندین فراخوانی LLM، تعاملات ابزاری و منطق شرطی باشند، اهمیت دارد.
*   **مدیریت تأخیر و هزینه:** عوامل هوش مصنوعی اغلب به LLMها و سایر APIهای خارجی متکی هستند که بر اساس تعداد توکن یا هر فراخوانی هزینه دارند. مشاهده‌پذیری امکان ردیابی دقیق این فراخوانی‌ها را فراهم می‌کند و به شناسایی عملیات‌هایی که بیش از حد کند یا پرهزینه هستند کمک می‌کند. این امر به تیم‌ها اجازه می‌دهد تا درخواست‌ها را بهینه کنند، مدل‌های کارآمدتری انتخاب کنند یا جریان‌های کاری را برای مدیریت هزینه‌های عملیاتی و اطمینان از تجربه کاربری خوب بازطراحی کنند.
*   **اعتماد، ایمنی و انطباق:** در بسیاری از برنامه‌ها، اطمینان از رفتار ایمن و اخلاقی عوامل اهمیت دارد. مشاهده‌پذیری یک ردپای حسابرسی از اقدامات و تصمیمات عامل فراهم می‌کند. این می‌تواند برای شناسایی و کاهش مشکلاتی مانند تزریق درخواست، تولید محتوای مضر یا سوءمدیریت اطلاعات شخصی قابل شناسایی (PII) استفاده شود. به‌عنوان مثال، می‌توانید ردیابی‌ها را بررسی کنید تا بفهمید چرا یک عامل پاسخ خاصی داده یا از یک ابزار خاص استفاده کرده است.
*   **حلقه‌های بهبود مستمر:** داده‌های مشاهده‌پذیری پایه‌ای برای یک فرآیند توسعه تکراری هستند. با نظارت بر عملکرد عوامل در دنیای واقعی، تیم‌ها می‌توانند زمینه‌های بهبود را شناسایی کنند، داده‌هایی برای تنظیم مدل‌ها جمع‌آوری کنند و تأثیر تغییرات را اعتبارسنجی کنند. این امر یک حلقه بازخورد ایجاد می‌کند که در آن بینش‌های تولید از ارزیابی آنلاین، آزمایش‌ها و اصلاحات آفلاین را اطلاع‌رسانی می‌کند و منجر به بهبود تدریجی عملکرد عامل می‌شود.

## معیارهای کلیدی برای ردیابی

برای نظارت و درک رفتار عامل، باید مجموعه‌ای از معیارها و سیگنال‌ها را ردیابی کنید. اگرچه معیارهای خاص ممکن است بسته به هدف عامل متفاوت باشند، برخی معیارها به‌طور کلی مهم هستند.

در اینجا برخی از رایج‌ترین معیارهایی که ابزارهای مشاهده‌پذیری ردیابی می‌کنند آورده شده است:

**تأخیر:** عامل با چه سرعتی پاسخ می‌دهد؟ زمان‌های انتظار طولانی تجربه کاربر را منفی تحت تأثیر قرار می‌دهد. باید تأخیر را برای وظایف و مراحل جداگانه با ردیابی اجرای عامل اندازه‌گیری کنید. به‌عنوان مثال، عاملی که برای تمام فراخوانی‌های مدل ۲۰ ثانیه زمان می‌برد، می‌تواند با استفاده از یک مدل سریع‌تر یا اجرای فراخوانی‌های مدل به‌صورت موازی تسریع شود.

**هزینه‌ها:** هزینه هر اجرای عامل چقدر است؟ عوامل هوش مصنوعی به فراخوانی‌های LLM که بر اساس تعداد توکن یا APIهای خارجی هزینه دارند متکی هستند. استفاده مکرر از ابزار یا درخواست‌های متعدد می‌تواند به‌سرعت هزینه‌ها را افزایش دهد. به‌عنوان مثال، اگر یک عامل پنج بار یک LLM را برای بهبود حاشیه‌ای کیفیت فراخوانی کند، باید ارزیابی کنید که آیا هزینه توجیه‌پذیر است یا می‌توانید تعداد فراخوانی‌ها را کاهش دهید یا از یک مدل ارزان‌تر استفاده کنید. نظارت بلادرنگ همچنین می‌تواند افزایش‌های غیرمنتظره (مثلاً اشکالاتی که باعث حلقه‌های API بیش از حد می‌شوند) را شناسایی کند.

**خطاهای درخواست:** چند درخواست عامل شکست خورده است؟ این می‌تواند شامل خطاهای API یا فراخوانی‌های ابزار ناموفق باشد. برای مقاوم‌تر کردن عامل خود در برابر این موارد در تولید، می‌توانید بازگشت‌ها یا تلاش‌های مجدد را تنظیم کنید. به‌عنوان مثال، اگر ارائه‌دهنده LLM A از کار افتاد، به ارائه‌دهنده LLM B به‌عنوان پشتیبان تغییر دهید.

**بازخورد کاربر:** اجرای ارزیابی‌های مستقیم کاربران بینش‌های ارزشمندی ارائه می‌دهد. این می‌تواند شامل رتبه‌بندی‌های صریح (👍/👎، ⭐۱-۵ ستاره) یا نظرات متنی باشد. بازخورد منفی مداوم باید شما را هشدار دهد زیرا این نشانه‌ای است که عامل همان‌طور که انتظار می‌رود کار نمی‌کند.

**بازخورد ضمنی کاربر:** رفتارهای کاربران حتی بدون رتبه‌بندی‌های صریح بازخورد غیرمستقیم ارائه می‌دهد. این می‌تواند شامل بازنویسی فوری پرسش، درخواست‌های تکراری یا کلیک روی دکمه تلاش مجدد باشد. به‌عنوان مثال، اگر مشاهده کنید که کاربران مکرراً یک پرسش را می‌پرسند، این نشانه‌ای است که عامل همان‌طور که انتظار می‌رود کار نمی‌کند.

**دقت:** عامل چند بار خروجی‌های صحیح یا مطلوب تولید می‌کند؟ تعاریف دقت متفاوت است (مثلاً صحت حل مسئله، دقت بازیابی اطلاعات، رضایت کاربر). اولین قدم تعریف موفقیت برای عامل شما است. می‌توانید دقت را از طریق بررسی‌های خودکار، امتیازات ارزیابی یا برچسب‌های تکمیل وظیفه ردیابی کنید. به‌عنوان مثال، ردیابی‌ها را به‌عنوان "موفق" یا "ناموفق" علامت‌گذاری کنید.

**معیارهای ارزیابی خودکار:** همچنین می‌توانید ارزیابی‌های خودکار را تنظیم کنید. به‌عنوان مثال، می‌توانید از یک LLM برای امتیازدهی به خروجی عامل استفاده کنید، مثلاً آیا مفید، دقیق یا خیر است. همچنین چندین کتابخانه متن‌باز وجود دارد که به شما کمک می‌کند جنبه‌های مختلف عامل را امتیازدهی کنید. به‌عنوان مثال، [RAGAS](https://docs.ragas.io/) برای عوامل RAG یا [LLM Guard](https://llm-guard.com/) برای شناسایی زبان مضر یا تزریق درخواست.

در عمل، ترکیبی از این معیارها بهترین پوشش را از سلامت عامل هوش مصنوعی ارائه می‌دهد. در دفترچه یادداشت [نمونه این فصل](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb)، نشان خواهیم داد که این معیارها در مثال‌های واقعی چگونه به نظر می‌رسند، اما ابتدا یاد می‌گیریم که یک جریان کاری ارزیابی معمولی چگونه است.

## ابزارسازی عامل خود

برای جمع‌آوری داده‌های ردیابی، باید کد خود را ابزارسازی کنید. هدف ابزارسازی کد عامل این است که ردیابی‌ها و معیارهایی تولید کند که بتوانند توسط یک پلتفرم مشاهده‌پذیری جمع‌آوری، پردازش و تجسم شوند.

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) به‌عنوان یک استاندارد صنعتی برای مشاهده‌پذیری LLM ظهور کرده است. این ابزار مجموعه‌ای از APIها، SDKها و ابزارها برای تولید، جمع‌آوری و صادرات داده‌های تله‌متری فراهم می‌کند.

کتابخانه‌های ابزارسازی زیادی وجود دارند که چارچوب‌های عامل موجود را پوشش می‌دهند و صادرات بخش‌های OpenTelemetry به یک ابزار مشاهده‌پذیری را آسان می‌کنند. در زیر یک مثال از ابزارسازی یک عامل AutoGen با کتابخانه ابزارسازی [OpenLit](https://github.com/openlit/openlit) آورده شده است:

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

دفترچه یادداشت [نمونه این فصل](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) نشان خواهد داد که چگونه عامل AutoGen خود را ابزارسازی کنید.

**ایجاد دستی بخش‌ها:** در حالی که کتابخانه‌های ابزارسازی یک پایه خوب فراهم می‌کنند، اغلب مواردی وجود دارد که اطلاعات دقیق‌تر یا سفارشی مورد نیاز است. می‌توانید بخش‌ها را به‌صورت دستی ایجاد کنید تا منطق برنامه سفارشی اضافه کنید. مهم‌تر از همه، می‌توانید بخش‌های ایجادشده به‌صورت خودکار یا دستی را با ویژگی‌های سفارشی (که به‌عنوان برچسب‌ها یا متاداده نیز شناخته می‌شوند) غنی کنید. این ویژگی‌ها می‌توانند شامل داده‌های خاص کسب‌وکار، محاسبات میانی یا هر زمینه‌ای باشند که ممکن است برای اشکال‌زدایی یا تحلیل مفید باشد، مانند `user_id`، `session_id` یا `model_version`.

مثالی از ایجاد ردیابی‌ها و بخش‌ها به‌صورت دستی با [Langfuse Python SDK](https://langfuse.com/docs/sdk/python/sdk-v3):

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## ارزیابی عامل

مشاهده‌پذیری به ما معیارها را می‌دهد، اما ارزیابی فرآیند تحلیل آن داده‌ها (و انجام آزمایش‌ها) برای تعیین عملکرد یک عامل هوش مصنوعی و چگونگی بهبود آن است. به عبارت دیگر، پس از داشتن آن ردیابی‌ها و معیارها، چگونه از آن‌ها برای قضاوت در مورد عامل و تصمیم‌گیری استفاده می‌کنید؟

ارزیابی منظم مهم است زیرا عوامل هوش مصنوعی اغلب غیرقطعی هستند و می‌توانند تکامل یابند (از طریق به‌روزرسانی‌ها یا تغییر رفتار مدل) – بدون ارزیابی، نمی‌دانید که آیا "عامل هوشمند" شما واقعاً کار خود را به‌خوبی انجام می‌دهد یا خیر.

دو دسته ارزیابی برای عوامل هوش مصنوعی وجود دارد: **ارزیابی آنلاین** و **ارزیابی آفلاین**. هر دو ارزشمند هستند و مکمل یکدیگرند. معمولاً با ارزیابی آفلاین شروع می‌کنیم، زیرا این حداقل گام لازم قبل از استقرار هر عاملی است.

### ارزیابی آفلاین

![موارد مجموعه داده در Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

این شامل ارزیابی عامل در یک محیط کنترل‌شده است، معمولاً با استفاده از مجموعه داده‌های آزمایشی، نه پرسش‌های زنده کاربران. شما از مجموعه داده‌های انتخاب‌شده‌ای استفاده می‌کنید که می‌دانید خروجی مورد انتظار یا رفتار صحیح چیست و سپس عامل خود را روی آن‌ها اجرا می‌کنید.

به‌عنوان مثال، اگر یک عامل حل مسئله ریاضی ساخته‌اید، ممکن است یک [مجموعه داده آزمایشی](https://huggingface.co/datasets/gsm8k) شامل ۱۰۰ مسئله با پاسخ‌های شناخته‌شده داشته باشید. ارزیابی آفلاین اغلب در طول توسعه انجام می‌شود (و می‌تواند بخشی از خطوط CI/CD باشد) تا بهبودها را بررسی کند یا از بازگشت‌ها جلوگیری کند. مزیت این است که **تکرارپذیر است و می‌توانید معیارهای دقت واضحی دریافت کنید زیرا حقیقت زمینی دارید**. همچنین ممکن است پرسش‌های کاربر را شبیه‌سازی کنید و پاسخ‌های عامل را با پاسخ‌های ایده‌آل مقایسه کنید یا از معیارهای خودکار همان‌طور که در بالا توضیح داده شد استفاده کنید.

چالش کلیدی در ارزیابی آفلاین اطمینان از جامعیت و به‌روز بودن مجموعه داده آزمایشی شما است – عامل ممکن است در یک مجموعه آزمایشی ثابت عملکرد خوبی داشته باشد اما با پرسش‌های بسیار متفاوتی در تولید مواجه شود. بنابراین، باید مجموعه‌های آزمایشی را با موارد خاص جدید و مثال‌هایی که سناریوهای دنیای واقعی را منعکس می‌کنند به‌روز نگه دارید. ترکیبی از موارد کوچک "آزمایش دود" و مجموعه‌های ارزیابی بزرگ‌تر مفید است: مجموعه‌های کوچک برای بررسی‌های سریع و مجموعه‌های بزرگ‌تر برای معیارهای عملکرد گسترده‌تر.

### ارزیابی آنلاین

![نمای کلی معیارهای مشاهده‌پذیری](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

این به ارزیابی عامل در یک محیط زنده و واقعی اشاره دارد، یعنی در طول استفاده واقعی در تولید. ارزیابی آنلاین شامل نظارت بر عملکرد عامل در تعاملات واقعی کاربران و تحلیل نتایج به‌صورت مداوم است.

به‌عنوان مثال، ممکن است نرخ‌های موفقیت، امتیازات رضایت کاربران یا سایر معیارها را در ترافیک زنده ردیابی کنید. مزیت ارزیابی آنلاین این است که **چیزهایی را که ممکن است در یک محیط آزمایشگاهی پیش‌بینی نکنید، ثبت می‌کند** – می‌توانید تغییرات مدل را در طول زمان مشاهده کنید (اگر اثربخشی عامل با تغییر الگوهای ورودی کاهش یابد) و پرسش‌ها یا موقعیت‌های غیرمنتظره‌ای را که در داده‌های آزمایشی شما نبودند، شناسایی کنید. این یک تصویر واقعی از رفتار عامل در دنیای واقعی ارائه می‌دهد.

ارزیابی آنلاین اغلب شامل جمع‌آوری بازخورد ضمنی و صریح کاربران، همان‌طور که بحث شد، و احتمالاً اجرای آزمایش‌های سایه یا A/B (که در آن نسخه جدیدی از عامل به‌صورت موازی برای مقایسه با نسخه قدیمی اجرا می‌شود). چالش این است که ممکن است برچسب‌ها یا امتیازات قابل‌اعتمادی برای تعاملات زنده دریافت نکنید – ممکن است به بازخورد کاربران یا معیارهای پایین‌دستی (مانند کلیک کاربر روی نتیجه) متکی باشید.

### ترکیب این دو

ارزیابی آنلاین و آفلاین متقابلاً انحصاری نیستند؛ آن‌ها به‌شدت مکمل یکدیگرند. بینش‌های حاصل از نظارت آنلاین (مثلاً انواع جدید پرسش‌های کاربر که عامل در آن‌ها عملکرد ضعیفی دارد) می‌توانند برای تقویت و بهبود مجموعه داده‌های آزمایشی آفلاین استفاده شوند. برعکس، عواملی که در آزمایش‌های آفلاین عملکرد خوبی دارند، می‌توانند با اطمینان بیشتری مستقر شده و به‌صورت آنلاین نظارت شوند.

در واقع، بسیاری از تیم‌ها یک حلقه را اتخاذ می‌کنند:

_ارزیابی آفلاین -> استقرار -> نظارت آنلاین -> جمع‌آوری موارد شکست جدید -> افزودن به مجموعه داده آفلاین -> اصلاح عامل -> تکرار._

## مشکلات رایج

هنگام استقرار عوامل هوش مصنوعی در تولید، ممکن است با چالش‌های مختلفی روبرو شوید. در اینجا برخی از مشکلات رایج و راه‌حل‌های احتمالی آن‌ها آورده شده است:

| **مشکل**    | **راه‌حل احتمالی**   |
| ------------- | ------------------ |
| عامل هوش مصنوعی وظایف را به‌طور مداوم انجام نمی‌دهد | - درخواست داده‌شده به عامل هوش مصنوعی را اصلاح کنید؛ اهداف را به‌وضوح مشخص کنید.<br>- شناسایی کنید که آیا تقسیم وظایف به زیروظایف و مدیریت آن‌ها توسط عوامل متعدد می‌تواند کمک کند. |
| عامل هوش مصنوعی در حلقه‌های مداوم گیر می‌کند  | - اطمینان حاصل کنید که شرایط و ضوابط خاتمه واضحی دارید تا عامل بداند چه زمانی باید فرآیند را متوقف کند.<br>- برای وظایف پیچیده‌ای که نیاز به استدلال و برنامه‌ریزی دارند، از یک مدل بزرگ‌تر که برای وظایف استدلال تخصصی شده است استفاده کنید. |
| فراخوانی‌های ابزار عامل هوش مصنوعی عملکرد خوبی ندارند   | - خروجی ابزار را خارج از سیستم عامل آزمایش و اعتبارسنجی کنید. |

- پارامترها، درخواست‌ها و نام‌گذاری ابزارها را بهبود دهید.  
| سیستم چندعاملی عملکرد ثابتی ندارد | - درخواست‌های داده‌شده به هر عامل را اصلاح کنید تا مشخص و متمایز از یکدیگر باشند.<br>- یک سیستم سلسله‌مراتبی با استفاده از یک عامل "مسیر‌یابی" یا کنترل‌کننده ایجاد کنید تا تعیین کند کدام عامل مناسب است. |

بسیاری از این مشکلات را می‌توان با استفاده از قابلیت مشاهده بهتر شناسایی کرد. ردیابی‌ها و معیارهایی که قبلاً بحث کردیم، به شناسایی دقیق محل وقوع مشکلات در جریان کاری عامل کمک می‌کنند و فرآیند اشکال‌زدایی و بهینه‌سازی را بسیار کارآمدتر می‌سازند.

## مدیریت هزینه‌ها

در اینجا چند استراتژی برای مدیریت هزینه‌های استقرار عوامل هوش مصنوعی در محیط تولید آورده شده است:

**استفاده از مدل‌های کوچک‌تر:** مدل‌های زبانی کوچک (SLM) می‌توانند در برخی از موارد استفاده عامل‌محور عملکرد خوبی داشته باشند و هزینه‌ها را به‌طور قابل‌توجهی کاهش دهند. همان‌طور که قبلاً اشاره شد، ایجاد یک سیستم ارزیابی برای تعیین و مقایسه عملکرد در مقابل مدل‌های بزرگ‌تر بهترین راه برای درک این است که یک SLM چقدر در مورد استفاده شما خوب عمل می‌کند. استفاده از SLMها را برای وظایف ساده‌تر مانند طبقه‌بندی نیت یا استخراج پارامتر در نظر بگیرید و مدل‌های بزرگ‌تر را برای استدلال‌های پیچیده‌تر نگه دارید.

**استفاده از مدل مسیریاب:** استراتژی مشابهی این است که از تنوعی از مدل‌ها و اندازه‌ها استفاده کنید. می‌توانید از یک LLM/SLM یا تابع بدون سرور برای مسیریابی درخواست‌ها بر اساس پیچیدگی به مدل‌های مناسب استفاده کنید. این کار نه‌تنها به کاهش هزینه‌ها کمک می‌کند، بلکه عملکرد را در وظایف مناسب تضمین می‌کند. به‌عنوان مثال، درخواست‌های ساده را به مدل‌های کوچک‌تر و سریع‌تر هدایت کنید و فقط از مدل‌های بزرگ و گران برای وظایف استدلال پیچیده استفاده کنید.

**ذخیره‌سازی پاسخ‌ها:** شناسایی درخواست‌ها و وظایف رایج و ارائه پاسخ‌ها قبل از عبور از سیستم عامل‌محور شما، راه خوبی برای کاهش حجم درخواست‌های مشابه است. حتی می‌توانید یک جریان برای شناسایی میزان شباهت یک درخواست به درخواست‌های ذخیره‌شده خود با استفاده از مدل‌های هوش مصنوعی پایه پیاده‌سازی کنید. این استراتژی می‌تواند هزینه‌ها را برای سؤالات متداول یا جریان‌های کاری رایج به‌طور قابل‌توجهی کاهش دهد.

## بیایید ببینیم این در عمل چگونه کار می‌کند

در [دفترچه نمونه این بخش](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb)، مثال‌هایی از نحوه استفاده از ابزارهای مشاهده‌پذیری برای نظارت و ارزیابی عامل خود را خواهیم دید.

## درس قبلی

[الگوی طراحی فراشناخت](../09-metacognition/README.md)

## درس بعدی

[MCP](../11-mcp/README.md)

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما تلاش می‌کنیم دقت را حفظ کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل خطاها یا نادرستی‌ها باشند. سند اصلی به زبان اصلی آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، توصیه می‌شود از ترجمه حرفه‌ای انسانی استفاده کنید. ما مسئولیتی در قبال سوء تفاهم‌ها یا تفسیرهای نادرست ناشی از استفاده از این ترجمه نداریم.