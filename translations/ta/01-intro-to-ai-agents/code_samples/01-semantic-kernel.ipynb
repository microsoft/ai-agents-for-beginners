{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# செமாண்டிக் கர்னல்\n",
    "\n",
    "இந்த குறியீட்டு மாதிரியில், நீங்கள் [செமாண்டிக் கர்னல்](https://aka.ms/ai-agents-beginners/semantic-kernel) AI Framework-ஐப் பயன்படுத்தி ஒரு அடிப்படை முகவரியை உருவாக்குவீர்கள்.\n",
    "\n",
    "இந்த மாதிரியின் நோக்கம், பின்னர் வேறு முகவரியின் முறைமைகளை செயல்படுத்தும் போது பயன்படுத்தப்படும் படிகளை உங்களுக்கு காட்டுவதாகும்.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## தேவையான பைதான் தொகுப்புகளை இறக்குமதி செய்யவும்\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from typing import Annotated\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.functions import kernel_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## கிளையன்ட் உருவாக்குதல்\n",
    "\n",
    "இந்த மாதிரியில், [GitHub Models](https://aka.ms/ai-agents-beginners/github-models) ஐ LLM-க்கு அணுகுவதற்காக பயன்படுத்துவோம்.\n",
    "\n",
    "`ai_model_id` என்பது `gpt-4o-mini` என வரையறுக்கப்பட்டுள்ளது. GitHub Models சந்தையில் கிடைக்கும் மற்றொரு மாடலுக்கு மாறி, வெவ்வேறு முடிவுகளைப் பார்க்க முயற்சிக்கவும்.\n",
    "\n",
    "GitHub Models க்கான `base_url` ஐ பயன்படுத்துவதற்காக `Azure Inference SDK` ஐ பயன்படுத்த வேண்டும். Semantic Kernel இல் உள்ள `OpenAIChatCompletion` இணைப்பியை பயன்படுத்துவோம். Semantic Kernel ஐ மற்ற மாடல் வழங்குநர்களுக்கு பயன்படுத்துவதற்கான [கிடைக்கக்கூடிய இணைப்பிகள்](https://learn.microsoft.com/semantic-kernel/concepts/ai-services/chat-completion) உள்ளன.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random   \n",
    "\n",
    "# Define a sample plugin for the sample\n",
    "\n",
    "class DestinationsPlugin:\n",
    "    \"\"\"A List of Random Destinations for a vacation.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # List of vacation destinations\n",
    "        self.destinations = [\n",
    "            \"Barcelona, Spain\",\n",
    "            \"Paris, France\",\n",
    "            \"Berlin, Germany\",\n",
    "            \"Tokyo, Japan\",\n",
    "            \"Sydney, Australia\",\n",
    "            \"New York, USA\",\n",
    "            \"Cairo, Egypt\",\n",
    "            \"Cape Town, South Africa\",\n",
    "            \"Rio de Janeiro, Brazil\",\n",
    "            \"Bali, Indonesia\"\n",
    "        ]\n",
    "        # Track last destination to avoid repeats\n",
    "        self.last_destination = None\n",
    "\n",
    "    @kernel_function(description=\"Provides a random vacation destination.\")\n",
    "    def get_random_destination(self) -> Annotated[str, \"Returns a random vacation destination.\"]:\n",
    "        # Get available destinations (excluding last one if possible)\n",
    "        available_destinations = self.destinations.copy()\n",
    "        if self.last_destination and len(available_destinations) > 1:\n",
    "            available_destinations.remove(self.last_destination)\n",
    "\n",
    "        # Select a random destination\n",
    "        destination = random.choice(available_destinations)\n",
    "\n",
    "        # Update the last destination\n",
    "        self.last_destination = destination\n",
    "\n",
    "        return destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = AsyncOpenAI(\n",
    "    api_key=os.environ.get(\"GITHUB_TOKEN\"), \n",
    "    base_url=\"https://models.inference.ai.azure.com/\",\n",
    ")\n",
    "\n",
    "# Create an AI Service that will be used by the `ChatCompletionAgent`\n",
    "chat_completion_service = OpenAIChatCompletion(\n",
    "    ai_model_id=\"gpt-4o-mini\",\n",
    "    async_client=client,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ஏஜென்டை உருவாக்குதல்\n",
    "\n",
    "கீழே, `TravelAgent` எனப்படும் ஏஜென்டை உருவாக்குகிறோம்.\n",
    "\n",
    "இந்த எடுத்துக்காட்டில், மிகவும் எளிய வழிமுறைகளை பயன்படுத்துகிறோம். இந்த வழிமுறைகளை மாற்றி, ஏஜென்ட் எப்படி வேறுபடுகிறதென்று பார்க்கலாம்.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ChatCompletionAgent(\n",
    "    service=chat_completion_service, \n",
    "    plugins=[DestinationsPlugin()],\n",
    "    name=\"TravelAgent\",\n",
    "    instructions=\"You are a helpful AI Agent that can help plan vacations for customers at random destinations\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ஏஜென்டை இயக்குதல்\n",
    "\n",
    "இப்போது `ChatHistoryAgentThread` வகை த்ரெட்டை வரையறுத்து ஏஜென்டை இயக்கலாம். தேவையான சிஸ்டம் செய்திகளை ஏஜென்டின் invoke_stream இன் `messages` கீவேர்ட் ஆர்க்யூமென்டில் வழங்கலாம்.\n",
    "\n",
    "இவை வரையறுக்கப்பட்ட பிறகு, `user_inputs` உருவாக்குகிறோம், இது பயனர் ஏஜென்டுக்கு அனுப்பும் தகவலாக இருக்கும். இந்தச் சூழலில், இந்த செய்தியை `Plan me a sunny vacation` என்று அமைத்துள்ளோம்.\n",
    "\n",
    "ஏஜென்டின் பதில் எப்படி மாறுகிறது என்பதைப் பார்க்க இந்த செய்தியை மாற்றுவதற்கு தயங்க வேண்டாம்.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    # Create a new thread for the agent\n",
    "    # If no thread is provided, a new thread will be\n",
    "    # created and returned with the initial response\n",
    "    thread: ChatHistoryAgentThread | None = None\n",
    "\n",
    "    user_inputs = [\n",
    "        \"Plan me a day trip.\",\n",
    "    ]\n",
    "\n",
    "    for user_input in user_inputs:\n",
    "        print(f\"# User: {user_input}\\n\")\n",
    "        first_chunk = True\n",
    "        async for response in agent.invoke_stream(\n",
    "            messages=user_input, thread=thread,\n",
    "        ):\n",
    "            # 5. Print the response\n",
    "            if first_chunk:\n",
    "                print(f\"# {response.name}: \", end=\"\", flush=True)\n",
    "                first_chunk = False\n",
    "            print(f\"{response}\", end=\"\", flush=True)\n",
    "            thread = response.thread\n",
    "        print()\n",
    "\n",
    "    # Clean up the thread\n",
    "    await thread.delete() if thread else None\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**குறிப்பு**:  \nஇந்த ஆவணம் [Co-op Translator](https://github.com/Azure/co-op-translator) என்ற AI மொழிபெயர்ப்பு சேவையைப் பயன்படுத்தி மொழிபெயர்க்கப்பட்டுள்ளது. நாங்கள் துல்லியத்திற்காக முயற்சிக்கின்றோம், ஆனால் தானியங்கி மொழிபெயர்ப்புகளில் பிழைகள் அல்லது தவறுகள் இருக்கக்கூடும் என்பதை தயவுசெய்து கவனத்தில் கொள்ளுங்கள். அதன் தாய்மொழியில் உள்ள மூல ஆவணம் அதிகாரப்பூர்வ ஆதாரமாக கருதப்பட வேண்டும். முக்கியமான தகவல்களுக்கு, தொழில்முறை மனித மொழிபெயர்ப்பு பரிந்துரைக்கப்படுகிறது. இந்த மொழிபெயர்ப்பைப் பயன்படுத்துவதால் ஏற்படும் எந்த தவறான புரிதல்கள் அல்லது தவறான விளக்கங்களுக்கு நாங்கள் பொறுப்பல்ல.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "coopTranslator": {
   "original_hash": "9faeec13969c8dff8a53f0933771d228",
   "translation_date": "2025-10-11T11:47:59+00:00",
   "source_file": "01-intro-to-ai-agents/code_samples/01-semantic-kernel.ipynb",
   "language_code": "ta"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}