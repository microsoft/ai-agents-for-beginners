<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "cdfd0acc8592c1af14f8637833450375",
  "translation_date": "2025-10-11T11:13:56+00:00",
  "source_file": "10-ai-agents-production/README.md",
  "language_code": "et"
}
-->
# AI-agentide kasutamine tootmises: J√§lgitavus ja hindamine

[![AI-agentid tootmises](../../../translated_images/lesson-10-thumbnail.2b79a30773db093e0b4fb47aaa618069e0afb4745fad4836526cf51df87f9ac9.et.png)](https://youtu.be/l4TP6IyJxmQ?si=reGOyeqjxFevyDq9)

Kui AI-agentid liiguvad eksperimentaalsetest protot√º√ºpidest reaalse maailma rakendustesse, muutub nende k√§itumise m√µistmine, j√µudluse j√§lgimine ja v√§ljundite s√ºstemaatiline hindamine √ºha olulisemaks.

## √ïpieesm√§rgid

P√§rast selle √µppetunni l√§bimist oskad/saad aru:
- Agentide j√§lgitavuse ja hindamise p√µhikontseptsioonidest
- Tehnikatest agentide j√µudluse, kulude ja t√µhususe parandamiseks
- Mida ja kuidas oma AI-agente s√ºstemaatiliselt hinnata
- Kuidas kontrollida kulusid AI-agentide tootmises kasutamisel
- Kuidas instrumenteerida AutoGeniga loodud agente

Eesm√§rk on anda sulle teadmised, et muuta oma "must kast" agentid l√§bipaistvateks, hallatavateks ja usaldusv√§√§rseteks s√ºsteemideks.

_**M√§rkus:** Oluline on juurutada AI-agente, mis on turvalised ja usaldusv√§√§rsed. Vaata [Usaldusv√§√§rsete AI-agentide loomine](./06-building-trustworthy-agents/README.md) √µppetundi._

## J√§ljed ja l√µigud

J√§lgitavuse t√∂√∂riistad, nagu [Langfuse](https://langfuse.com/) v√µi [Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry), esindavad agentide t√∂√∂vooge tavaliselt j√§lgede ja l√µikudena.

- **J√§lg** t√§histab t√§ielikku agenti √ºlesannet algusest l√µpuni (n√§iteks kasutaja p√§ringu k√§sitlemine).
- **L√µigud** on individuaalsed sammud j√§lje sees (n√§iteks keelemudeli kutsumine v√µi andmete hankimine).

![J√§lgede puu Langfuses](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

Ilma j√§lgitavuseta v√µib AI-agent tunduda nagu "must kast" ‚Äì selle sisemine olek ja p√µhjendused on l√§bipaistmatud, mist√µttu on raske probleeme diagnoosida v√µi j√µudlust optimeerida. J√§lgitavusega muutuvad agendid "klaaskastideks", pakkudes l√§bipaistvust, mis on h√§davajalik usalduse loomiseks ja tagamaks, et nad t√∂√∂tavad kavandatud viisil.

## Miks j√§lgitavus on tootmiskeskkondades oluline

AI-agentide viimine tootmiskeskkondadesse toob kaasa uued v√§ljakutsed ja n√µuded. J√§lgitavus ei ole enam lihtsalt "hea, kui on", vaid kriitiline v√µimekus:

*   **Vigade ja algp√µhjuste anal√º√ºs:** Kui agent eba√µnnestub v√µi annab ootamatu v√§ljundi, pakuvad j√§lgitavuse t√∂√∂riistad vajalikke j√§lgi, et tuvastada vea allikas. See on eriti oluline keerukate agentide puhul, mis v√µivad h√µlmata mitut LLM-i kutset, t√∂√∂riistade interaktsioone ja tingimuslikku loogikat.
*   **Latentsuse ja kulude haldamine:** AI-agentid tuginevad sageli LLM-idele ja teistele v√§listele API-dele, mille eest arveldatakse m√§rgi v√µi kutse alusel. J√§lgitavus v√µimaldab t√§pselt j√§lgida neid kutseid, aidates tuvastada operatsioone, mis on liialt aeglased v√µi kallid. See v√µimaldab meeskondadel optimeerida juhiseid, valida t√µhusamaid mudeleid v√µi √ºmber kujundada t√∂√∂vooge, et hallata tegevuskulusid ja tagada hea kasutajakogemus.
*   **Usaldus, turvalisus ja vastavus:** Paljudes rakendustes on oluline tagada, et agendid k√§ituksid turvaliselt ja eetiliselt. J√§lgitavus pakub agentide tegevuste ja otsuste auditeerimisj√§lge. Seda saab kasutada probleemide, nagu juhiste s√ºstimine, kahjuliku sisu genereerimine v√µi isikuandmete v√§√§rkasutamine, tuvastamiseks ja leevendamiseks. N√§iteks saate j√§lgi √ºle vaadata, et m√µista, miks agent andis teatud vastuse v√µi kasutas konkreetset t√∂√∂riista.
*   **Pideva t√§iustamise ts√ºklid:** J√§lgitavuse andmed on iteratiivse arendusprotsessi alus. J√§lgides, kuidas agendid p√§riselus toimivad, saavad meeskonnad tuvastada parendamisvaldkondi, koguda andmeid mudelite peenh√§√§lestamiseks ja valideerida muudatuste m√µju. See loob tagasiside ts√ºkli, kus tootmise √ºlevaated veebip√µhisest hindamisest informeerivad offline-eksperimente ja t√§iustusi, viies j√§rk-j√§rgult parema agentide j√µudluseni.

## Olulised m√µ√µdikud j√§lgimiseks

Agentide k√§itumise j√§lgimiseks ja m√µistmiseks tuleks j√§lgida mitmesuguseid m√µ√µdikuid ja signaale. Kuigi konkreetsed m√µ√µdikud v√µivad varieeruda s√µltuvalt agendi eesm√§rgist, on m√µned universaalselt olulised.

Siin on m√µned k√µige levinumad m√µ√µdikud, mida j√§lgitavuse t√∂√∂riistad j√§lgivad:

**Latentsus:** Kui kiiresti agent reageerib? Pikad ooteajad m√µjutavad kasutajakogemust negatiivselt. Latentsust tuleks m√µ√µta nii √ºlesannete kui ka individuaalsete sammude puhul, j√§lgides agentide t√∂√∂vooge. N√§iteks agent, kes kulutab k√µigile mudelikutsetele 20 sekundit, v√µiks kiirendada, kasutades kiiremat mudelit v√µi k√§ivitades mudelikutsed paralleelselt.

**Kulud:** Milline on kulu agendi t√∂√∂voo kohta? AI-agentid tuginevad LLM-kutsetele, mille eest arveldatakse m√§rgi alusel, v√µi v√§listele API-dele. Sagedane t√∂√∂riistade kasutamine v√µi mitmed juhised v√µivad kulud kiiresti t√µsta. N√§iteks kui agent kutsub LLM-i viis korda marginaalse kvaliteedi parandamiseks, tuleb hinnata, kas kulu on √µigustatud v√µi kas kutsete arvu saab v√§hendada v√µi kasutada odavamat mudelit. Reaalajas j√§lgimine aitab tuvastada ka ootamatuid kulut√µuse (nt vead, mis p√µhjustavad liigseid API-ts√ºkleid).

**P√§ringute vead:** Kui palju p√§ringuid agent eba√µnnestus? See v√µib h√µlmata API-vigu v√µi eba√µnnestunud t√∂√∂riistakutseid. Agendi tootmises vastupidavamaks muutmiseks saate seadistada varuplaanid v√µi korduskatsed. N√§iteks kui LLM-i pakkuja A on maas, l√ºlitute varuplaanina LLM-i pakkujale B.

**Kasutajate tagasiside:** Otsene kasutajate hindamine annab v√§√§rtuslikku teavet. See v√µib h√µlmata selgeid hinnanguid (üëçp√∂idlad √ºles/üëéalla, ‚≠ê1-5 t√§rni) v√µi tekstilisi kommentaare. Pidev negatiivne tagasiside peaks teid hoiatama, kuna see viitab sellele, et agent ei t√∂√∂ta ootusp√§raselt.

**Kaudne kasutajate tagasiside:** Kasutajate k√§itumine annab kaudset tagasisidet isegi ilma selgete hinnanguteta. See v√µib h√µlmata kohest k√ºsimuse √ºmber s√µnastamist, korduvaid p√§ringuid v√µi nupule "proovi uuesti" kl√µpsamist. N√§iteks kui n√§ete, et kasutajad k√ºsivad korduvalt sama k√ºsimust, on see m√§rk, et agent ei t√∂√∂ta ootusp√§raselt.

**T√§psus:** Kui sageli agent genereerib √µigeid v√µi soovitud v√§ljundeid? T√§psuse m√§√§ratlused varieeruvad (nt probleemide lahendamise korrektsus, teabe hankimise t√§psus, kasutajate rahulolu). Esimene samm on m√§√§ratleda, milline edu agendi jaoks v√§lja n√§eb. T√§psust saab j√§lgida automatiseeritud kontrollide, hindamisskooride v√µi √ºlesannete l√µpetamise siltide kaudu. N√§iteks j√§lgede m√§rkimine kui "√µnnestunud" v√µi "eba√µnnestunud".

**Automatiseeritud hindamism√µ√µdikud:** V√µite seadistada ka automatiseeritud hindamisi. N√§iteks saate kasutada LLM-i, et hinnata agendi v√§ljundit, nt kas see on kasulik, t√§pne v√µi mitte. Samuti on mitmeid avatud l√§htekoodiga teeke, mis aitavad hinnata agendi erinevaid aspekte. N√§iteks [RAGAS](https://docs.ragas.io/) RAG-agentide jaoks v√µi [LLM Guard](https://llm-guard.com/) kahjuliku keele v√µi juhiste s√ºstimise tuvastamiseks.

Praktikas annab nende m√µ√µdikute kombinatsioon parima √ºlevaate AI-agendi tervisest. Selle peat√ºki [n√§idisp√§evikus](./code_samples/10_autogen_evaluation.ipynb) n√§itame, kuidas need m√µ√µdikud n√§evad v√§lja reaalsetes n√§idetes, kuid k√µigepealt √µpime, kuidas t√º√ºpiline hindamisvoog v√§lja n√§eb.

## Instrumenteerige oma agent

J√§lgimisandmete kogumiseks peate oma koodi instrumenteerima. Eesm√§rk on instrumenteerida agendi kood nii, et see edastaks j√§lgi ja m√µ√µdikuid, mida j√§lgitavuse platvorm saab koguda, t√∂√∂delda ja visualiseerida.

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) on kujunenud t√∂√∂stusstandardiks LLM-i j√§lgitavuse jaoks. See pakub API-de, SDK-de ja t√∂√∂riistade komplekti telemeetriaandmete genereerimiseks, kogumiseks ja eksportimiseks.

On palju instrumenteerimise teeke, mis pakuvad olemasolevatele agendiraamistikele m√§hiseid ja muudavad OpenTelemetry l√µikude eksportimise j√§lgitavuse t√∂√∂riistale lihtsaks. Allpool on n√§ide AutoGen-agendi instrumenteerimisest [OpenLit instrumenteerimise teegiga](https://github.com/openlit/openlit):

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

Selle peat√ºki [n√§idisp√§evik](./code_samples/10_autogen_evaluation.ipynb) demonstreerib, kuidas instrumenteerida oma AutoGen-agent.

**Manuaalne l√µikude loomine:** Kuigi instrumenteerimise teegid pakuvad head alust, on sageli juhtumeid, kus on vaja √ºksikasjalikumat v√µi kohandatud teavet. L√µike saab k√§sitsi luua, et lisada kohandatud rakendusloogikat. Veelgi olulisem on see, et automaatselt v√µi k√§sitsi loodud l√µike saab rikastada kohandatud atribuutidega (tuntud ka kui sildid v√µi metaandmed). Need atribuudid v√µivad h√µlmata √§rispetsiifilisi andmeid, vahepealseid arvutusi v√µi konteksti, mis v√µib olla kasulik silumiseks v√µi anal√º√ºsiks, n√§iteks `user_id`, `session_id` v√µi `model_version`.

N√§ide j√§lgede ja l√µikude k√§sitsi loomisest [Langfuse Python SDK-ga](https://langfuse.com/docs/sdk/python/sdk-v3):

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## Agendi hindamine

J√§lgitavus annab meile m√µ√µdikud, kuid hindamine on protsess, kus neid andmeid anal√º√ºsitakse (ja teste tehakse), et m√§√§rata, kui h√§sti AI-agent toimib ja kuidas seda saab parandada. Teisis√µnu, kui teil on need j√§ljed ja m√µ√µdikud, kuidas neid kasutada agendi hindamiseks ja otsuste tegemiseks?

Regulaarne hindamine on oluline, kuna AI-agentid on sageli mitte-deterministlikud ja v√µivad areneda (l√§bi uuenduste v√µi mudeli k√§itumise muutumise) ‚Äì ilma hindamiseta ei tea, kas teie "nutikas agent" teeb tegelikult oma t√∂√∂d h√§sti v√µi on ta halvenenud.

AI-agentide hindamiseks on kaks kategooriat: **veebip√µhine hindamine** ja **offline-hindamine**. M√µlemad on v√§√§rtuslikud ja t√§iendavad teineteist. Tavaliselt alustame offline-hindamisest, kuna see on minimaalne vajalik samm enne agendi juurutamist.

### Offline-hindamine

![Andmekogumi √ºksused Langfuses](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

See h√µlmab agendi hindamist kontrollitud keskkonnas, tavaliselt testandmekogumite abil, mitte reaalajas kasutajap√§ringutega. Kasutatakse kureeritud andmekogumeid, kus teate, milline on oodatav v√§ljund v√µi √µige k√§itumine, ja seej√§rel k√§ivitate agendi nende peal.

N√§iteks kui olete loonud matemaatiliste s√µnaprobleemide agendi, v√µib teil olla [testandmekogum](https://huggingface.co/datasets/gsm8k) 100 probleemiga, mille vastused on teada. Offline-hindamist tehakse sageli arenduse ajal (ja see v√µib olla osa CI/CD torujuhtmetest), et kontrollida t√§iustusi v√µi kaitsta regressioonide eest. Eeliseks on see, et see on **korduv ja saate selged t√§psusm√µ√µdikud, kuna teil on t√µeandmed**. V√µite simuleerida ka kasutajap√§ringuid ja m√µ√µta agendi vastuseid ideaalsete vastuste vastu v√µi kasutada automatiseeritud m√µ√µdikuid, nagu eespool kirjeldatud.

Offline-hindamise peamine v√§ljakutse on tagada, et teie testandmekogum oleks terviklik ja j√§√§ks asjakohaseks ‚Äì agent v√µib fikseeritud testikomplektis h√§sti toimida, kuid tootmises kohtab v√§ga erinevaid p√§ringuid. Seet√µttu peaksite testikomplekte v√§rskendama uute erandjuhtumite ja n√§idetega, mis kajastavad reaalseid stsenaariume‚Äã. Kasulik on kasutada v√§ikeste "kiirtestide" juhtumite ja suuremate hindamiskomplektide segu: v√§ikesed komplektid kiireks kontrolliks ja suuremad laiemate j√µudlusm√µ√µdikute jaoks‚Äã.

### Veebip√µhine hindamine

![J√§lgitavuse m√µ√µdikute √ºlevaade](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

See viitab agendi hindamisele reaalajas, reaalses keskkonnas, st tootmises tegeliku kasutamise ajal. Veebip√µhine hindamine h√µlmab agendi j√µudluse j√§lgimist reaalsete kasutajate interaktsioonide p√µhjal ja tulemuste pidevat anal√º√ºsi.

N√§iteks v√µite j√§lgida edukuse m√§√§rasid, kasutajate rahulolu skoori v√µi muid m√µ√µdikuid reaalajas liikluse p√µhjal. Veebip√µhise hindamise eeliseks on see, et see **p√º√ºab kinni asju, mida te laborikeskkonnas ei pruugi ette n√§ha** ‚Äì saate j√§lgida mudeli triivimist aja jooksul (kui agendi t√µhusus halveneb sisendmustrite muutumisel) ja tuvastada ootamatuid p√§ringuid v√µi olukordi, mida teie testandmetes ei olnud‚Äã. See annab t√µese pildi sellest, kuidas agent metsikus looduses k√§itub.

Veebip√µhine hindamine h√µlmab sageli kaudse ja otsese kasutajate tagasiside kogumist, nagu eespool arutatud, ning v√µimalusel varjuteste v√µi A/B-testide l√§biviimist (kus agendi uus versioon t√∂√∂tab paralleelselt vana versiooniga v√µrdlemiseks). V√§ljakutseks on see, et reaalajas interaktsioonide jaoks usaldusv√§√§rsete siltide v√µi skooride saamine v√µib olla keeruline ‚Äì v√µite tugineda kasutajate tagasisidele v√µi allavoolu m√µ√µdikutele (n√§iteks kas kasutaja kl√µpsas tulemusel).

### Kahe kombineerimine

Veebip√µhine ja offline-hindamine ei ole vastastikku v√§listavad; need t√§iendavad teineteist suurep√§raselt. Veebip√µhise j√§lgimise √ºlevaated (nt uued kasutajap√§ringute t√º√ºbid, kus agent halvasti toimib) saab kasutada offline-testandmekogumite t√§iendamiseks ja parandamiseks. Vastupidi, agendid, kes offline-testides h√§sti toimivad, saab seej√§rel enesekindlamalt juurutada ja veebis j√§lgida.

Tegelikult kasutavad paljud meeskonnad ts√ºklit:

_hinda offline -> juuruta -> j√§lgi veebis -> kogu uusi eba√µnnestumisi -> lisa offline-andmekogumisse -> t√§iusta agenti -> korda_.

## Levinud probleemid

AI-agentide tootmises juurutamisel v√µite kohata mitmesuguseid v√§ljakutseid. Siin on m√µned levinud probleemid ja nende v√µimalikud lahendused:

| **Probleem**    | **V√µimalik lahendus**   |
| ------------- | ------------------ |
| AI-agent ei t√§ida √ºlesandeid j√§rjekindlalt | - T√§psusta agendile antud juhiseid; ole eesm√§rkides selge.<br>- Tuvasta, kus √ºlesannete jagamine alam√ºlesanneteks ja nende k√§sitlemine mitme agendi poolt v√µib aidata. |
| AI-agent satub pidevatesse ts√ºklitesse  | - Veendu, et sul oleksid selged l√µpetamise tingimused, et agent teaks, millal protsess l√µpetada.<br>- Keerukate √ºlesannete puhul, mis n√µuavad p√µhjendamist ja planeerimist, kasuta suuremat mudelit, mis on spetsialiseerunud p√µhjendamis√ºlesannetele. |
| AI-agendi t√∂√∂riistakutsed ei toimi h√§sti   | - Testi ja valideeri t√∂√∂riista v√§ljund
Siin on m√µned strateegiad, kuidas hallata AI agentide tootmisesse juurutamise kulusid:

**V√§iksemate mudelite kasutamine:** V√§ikesed keelemudelid (SLM-id) v√µivad teatud agentlike kasutusjuhtude puhul h√§sti toimida ja kulusid oluliselt v√§hendada. Nagu varem mainitud, on parim viis m√µista, kui h√§sti SLM teie kasutusjuhtumi puhul toimib, luua hindamiss√ºsteem, et m√§√§rata ja v√µrrelda nende j√µudlust suuremate mudelitega. Kaaluge SLM-ide kasutamist lihtsamate √ºlesannete jaoks, nagu kavatsuste klassifitseerimine v√µi parameetrite eraldamine, ning j√§tke suuremad mudelid keerukamate m√µtlemis√ºlesannete jaoks.

**Routingu mudeli kasutamine:** Sarnane strateegia on kasutada erinevaid mudeleid ja suurusi. V√µite kasutada LLM/SLM-i v√µi serverivaba funktsiooni, et suunata p√§ringud keerukuse alusel sobivaimatele mudelitele. See aitab samuti kulusid v√§hendada, tagades samal ajal √µige √ºlesande jaoks sobiva j√µudluse. N√§iteks suunake lihtsad p√§ringud v√§iksematele ja kiirematele mudelitele ning kasutage kallimaid suuri mudeleid ainult keerukate m√µtlemis√ºlesannete jaoks.

**Vastuste vahem√§llu salvestamine:** Tavaliste p√§ringute ja √ºlesannete tuvastamine ning vastuste pakkumine enne, kui need j√µuavad teie agentlikku s√ºsteemi, on hea viis sarnaste p√§ringute mahu v√§hendamiseks. V√µite isegi rakendada voogu, et tuvastada, kui sarnane p√§ring on teie vahem√§llu salvestatud p√§ringutega, kasutades lihtsamaid AI-mudeleid. See strateegia v√µib m√§rkimisv√§√§rselt v√§hendada kulusid korduma kippuvate k√ºsimuste v√µi tavap√§raste t√∂√∂voogude puhul.

## Vaatame, kuidas see praktikas toimib

Selle jaotise [n√§idisp√§evikus](./code_samples/10_autogen_evaluation.ipynb) n√§eme n√§iteid, kuidas kasutada j√§lgitavuse t√∂√∂riistu oma agendi j√§lgimiseks ja hindamiseks.

### Kas teil on rohkem k√ºsimusi AI agentide tootmisesse viimise kohta?

Liituge [Azure AI Foundry Discordiga](https://aka.ms/ai-agents/discord), et kohtuda teiste √µppijatega, osaleda vastuv√µtutundides ja saada vastuseid oma AI agentide k√ºsimustele.

## Eelmine √µppetund

[Metakognitsiooni disainimuster](../09-metacognition/README.md)

## J√§rgmine √µppetund

[Agentlikud protokollid](../11-agentic-protocols/README.md)

---

**Lahti√ºtlus**:  
See dokument on t√µlgitud AI t√µlketeenuse [Co-op Translator](https://github.com/Azure/co-op-translator) abil. Kuigi p√º√ºame tagada t√§psust, palume arvestada, et automaatsed t√µlked v√µivad sisaldada vigu v√µi ebat√§psusi. Algne dokument selle algses keeles tuleks pidada autoriteetseks allikaks. Olulise teabe puhul soovitame kasutada professionaalset inimt√µlget. Me ei vastuta selle t√µlke kasutamisest tulenevate arusaamatuste v√µi valesti t√µlgenduste eest.