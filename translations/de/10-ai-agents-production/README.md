<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8164484c16b1ed3287ef9dae9fc437c1",
  "translation_date": "2025-07-24T07:35:40+00:00",
  "source_file": "10-ai-agents-production/README.md",
  "language_code": "de"
}
-->
# KI-Agenten in der Produktion: Beobachtbarkeit & Bewertung

Wenn KI-Agenten von experimentellen Prototypen zu realen Anwendungen √ºbergehen, wird die F√§higkeit, ihr Verhalten zu verstehen, ihre Leistung zu √ºberwachen und ihre Ergebnisse systematisch zu bewerten, entscheidend.

## Lernziele

Nach Abschluss dieser Lektion wirst du wissen/verstehen:
- Die grundlegenden Konzepte der Beobachtbarkeit und Bewertung von Agenten
- Techniken zur Verbesserung der Leistung, Kosten und Effektivit√§t von Agenten
- Was und wie du deine KI-Agenten systematisch bewerten kannst
- Wie du Kosten bei der Bereitstellung von KI-Agenten in der Produktion kontrollierst
- Wie du Agenten, die mit AutoGen erstellt wurden, instrumentierst

Das Ziel ist, dir das Wissen zu vermitteln, um deine "Black-Box"-Agenten in transparente, handhabbare und zuverl√§ssige Systeme zu verwandeln.

_**Hinweis:** Es ist wichtig, KI-Agenten bereitzustellen, die sicher und vertrauensw√ºrdig sind. Sieh dir die Lektion [Vertrauensw√ºrdige KI-Agenten aufbauen](./06-building-trustworthy-agents/README.md) an._

## Traces und Spans

Beobachtungswerkzeuge wie [Langfuse](https://langfuse.com/) oder [Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry) stellen Agentenl√§ufe √ºblicherweise als Traces und Spans dar.

- **Trace** repr√§sentiert eine vollst√§ndige Agentenaufgabe von Anfang bis Ende (z. B. die Bearbeitung einer Benutzeranfrage).
- **Spans** sind einzelne Schritte innerhalb des Traces (z. B. der Aufruf eines Sprachmodells oder das Abrufen von Daten).

![Trace-Baum in Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

Ohne Beobachtbarkeit kann sich ein KI-Agent wie eine "Black Box" anf√ºhlen ‚Äì sein interner Zustand und seine Entscheidungsfindung sind undurchsichtig, was es schwierig macht, Probleme zu diagnostizieren oder die Leistung zu optimieren. Mit Beobachtbarkeit werden Agenten zu "Glass Boxes", die Transparenz bieten, die f√ºr den Aufbau von Vertrauen und die Sicherstellung eines ordnungsgem√§√üen Betriebs unerl√§sslich ist.

## Warum Beobachtbarkeit in Produktionsumgebungen wichtig ist

Der √úbergang von KI-Agenten in Produktionsumgebungen bringt neue Herausforderungen und Anforderungen mit sich. Beobachtbarkeit ist nicht mehr nur ein "Nice-to-have", sondern eine kritische F√§higkeit:

*   **Fehlerbehebung und Ursachenanalyse**: Wenn ein Agent fehlschl√§gt oder unerwartete Ergebnisse liefert, bieten Beobachtungswerkzeuge die Traces, die ben√∂tigt werden, um die Fehlerquelle zu identifizieren. Dies ist besonders wichtig bei komplexen Agenten, die mehrere LLM-Aufrufe, Werkzeuginteraktionen und bedingte Logik umfassen k√∂nnen.
*   **Latenz- und Kostenmanagement**: KI-Agenten verlassen sich oft auf LLMs und andere externe APIs, die pro Token oder pro Aufruf abgerechnet werden. Beobachtbarkeit erm√∂glicht eine pr√§zise Nachverfolgung dieser Aufrufe, um Operationen zu identifizieren, die √ºberm√§√üig langsam oder teuer sind. So k√∂nnen Teams Prompts optimieren, effizientere Modelle ausw√§hlen oder Workflows neu gestalten, um Betriebskosten zu senken und eine gute Benutzererfahrung sicherzustellen.
*   **Vertrauen, Sicherheit und Compliance**: In vielen Anwendungen ist es wichtig, sicherzustellen, dass Agenten sicher und ethisch handeln. Beobachtbarkeit bietet eine Pr√ºfspur der Aktionen und Entscheidungen eines Agenten. Diese kann genutzt werden, um Probleme wie Prompt Injection, die Generierung sch√§dlicher Inhalte oder den unsachgem√§√üen Umgang mit personenbezogenen Daten (PII) zu erkennen und zu beheben. Zum Beispiel kannst du Traces √ºberpr√ºfen, um zu verstehen, warum ein Agent eine bestimmte Antwort gegeben oder ein bestimmtes Werkzeug verwendet hat.
*   **Kontinuierliche Verbesserungszyklen**: Beobachtungsdaten bilden die Grundlage eines iterativen Entwicklungsprozesses. Durch die √úberwachung der Leistung von Agenten in der realen Welt k√∂nnen Teams Verbesserungsbereiche identifizieren, Daten f√ºr die Feinabstimmung von Modellen sammeln und die Auswirkungen von √Ñnderungen validieren. Dies schafft einen Feedback-Zyklus, bei dem Produktionseinblicke aus der Online-Bewertung die Offline-Experimente und -Verfeinerungen informieren, was zu einer schrittweisen Verbesserung der Agentenleistung f√ºhrt.

## Wichtige Kennzahlen zur √úberwachung

Um das Verhalten eines Agenten zu √ºberwachen und zu verstehen, sollten verschiedene Kennzahlen und Signale verfolgt werden. W√§hrend die spezifischen Kennzahlen je nach Zweck des Agenten variieren k√∂nnen, gibt es einige, die universell wichtig sind.

Hier sind einige der h√§ufigsten Kennzahlen, die von Beobachtungswerkzeugen √ºberwacht werden:

**Latenz:** Wie schnell reagiert der Agent? Lange Wartezeiten beeintr√§chtigen die Benutzererfahrung. Du solltest die Latenz f√ºr Aufgaben und einzelne Schritte durch die Nachverfolgung von Agentenl√§ufen messen. Zum Beispiel k√∂nnte ein Agent, der 20 Sekunden f√ºr alle Modellaufrufe ben√∂tigt, durch die Verwendung eines schnelleren Modells oder durch parallele Modellaufrufe beschleunigt werden.

**Kosten:** Wie hoch sind die Kosten pro Agentenlauf? KI-Agenten verlassen sich auf LLM-Aufrufe, die pro Token oder externe APIs abgerechnet werden. H√§ufige Werkzeugnutzung oder mehrere Prompts k√∂nnen die Kosten schnell in die H√∂he treiben. Zum Beispiel, wenn ein Agent ein LLM f√ºnfmal aufruft, um eine marginale Qualit√§tsverbesserung zu erzielen, musst du bewerten, ob die Kosten gerechtfertigt sind oder ob du die Anzahl der Aufrufe reduzieren oder ein g√ºnstigeres Modell verwenden k√∂nntest. Echtzeit√ºberwachung kann auch unerwartete Spitzen identifizieren (z. B. Fehler, die √ºberm√§√üige API-Schleifen verursachen).

**Anfragefehler:** Wie viele Anfragen hat der Agent nicht erf√ºllt? Dies kann API-Fehler oder fehlgeschlagene Werkzeugaufrufe umfassen. Um deinen Agenten in der Produktion robuster gegen solche Fehler zu machen, kannst du Fallbacks oder Wiederholungen einrichten. Zum Beispiel, wenn LLM-Anbieter A ausf√§llt, wechselst du zu LLM-Anbieter B als Backup.

**Benutzerfeedback:** Die Implementierung direkter Benutzerevaluierungen liefert wertvolle Einblicke. Dies kann explizite Bewertungen (üëçDaumen hoch/üëérunter, ‚≠ê1-5 Sterne) oder Textkommentare umfassen. Konsistentes negatives Feedback sollte dich alarmieren, da dies ein Zeichen daf√ºr ist, dass der Agent nicht wie erwartet funktioniert.

**Implizites Benutzerfeedback:** Benutzerverhalten liefert indirektes Feedback, auch ohne explizite Bewertungen. Dazu geh√∂ren sofortige Frageumformulierungen, wiederholte Anfragen oder das Klicken auf eine Wiederholungsschaltfl√§che. Zum Beispiel, wenn du siehst, dass Benutzer wiederholt dieselbe Frage stellen, ist dies ein Zeichen daf√ºr, dass der Agent nicht wie erwartet funktioniert.

**Genauigkeit:** Wie oft liefert der Agent korrekte oder w√ºnschenswerte Ergebnisse? Die Definition von Genauigkeit variiert (z. B. Probleml√∂sungsgenauigkeit, Genauigkeit bei der Informationsbeschaffung, Benutzerzufriedenheit). Der erste Schritt besteht darin, zu definieren, wie Erfolg f√ºr deinen Agenten aussieht. Du kannst die Genauigkeit durch automatisierte Pr√ºfungen, Bewertungsscores oder Aufgabenabschlusskennzeichnungen verfolgen. Zum Beispiel, indem du Traces als "erfolgreich" oder "fehlgeschlagen" markierst.

**Automatisierte Bewertungskennzahlen:** Du kannst auch automatisierte Bewertungen einrichten. Zum Beispiel kannst du ein LLM verwenden, um die Ausgabe des Agenten zu bewerten, z. B. ob sie hilfreich, genau oder nicht ist. Es gibt auch mehrere Open-Source-Bibliotheken, die dir helfen, verschiedene Aspekte des Agenten zu bewerten. Zum Beispiel [RAGAS](https://docs.ragas.io/) f√ºr RAG-Agenten oder [LLM Guard](https://llm-guard.com/), um sch√§dliche Sprache oder Prompt Injection zu erkennen.

In der Praxis bietet eine Kombination dieser Kennzahlen die beste Abdeckung f√ºr die Gesundheit eines KI-Agenten. Im [Beispiel-Notebook](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) dieses Kapitels zeigen wir dir, wie diese Kennzahlen in realen Beispielen aussehen, aber zuerst lernen wir, wie ein typischer Bewertungsworkflow aussieht.

## Instrumentiere deinen Agenten

Um Tracing-Daten zu sammeln, musst du deinen Code instrumentieren. Ziel ist es, den Agenten-Code so zu instrumentieren, dass Traces und Kennzahlen erzeugt werden, die von einer Beobachtungsplattform erfasst, verarbeitet und visualisiert werden k√∂nnen.

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) hat sich als Industriestandard f√ºr die Beobachtbarkeit von LLMs etabliert. Es bietet eine Reihe von APIs, SDKs und Tools zur Generierung, Sammlung und Export von Telemetriedaten.

Es gibt viele Instrumentierungsbibliotheken, die bestehende Agenten-Frameworks umschlie√üen und das Exportieren von OpenTelemetry-Spans an ein Beobachtungswerkzeug erleichtern. Unten findest du ein Beispiel f√ºr die Instrumentierung eines AutoGen-Agenten mit der [OpenLit-Instrumentierungsbibliothek](https://github.com/openlit/openlit):

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

Das [Beispiel-Notebook](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) in diesem Kapitel zeigt dir, wie du deinen AutoGen-Agenten instrumentierst.

**Manuelle Span-Erstellung:** W√§hrend Instrumentierungsbibliotheken eine gute Grundlage bieten, gibt es oft F√§lle, in denen detailliertere oder benutzerdefinierte Informationen ben√∂tigt werden. Du kannst Spans manuell erstellen, um benutzerdefinierte Anwendungslogik hinzuzuf√ºgen. Wichtiger ist, dass sie automatisch oder manuell erstellte Spans mit benutzerdefinierten Attributen (auch als Tags oder Metadaten bekannt) anreichern k√∂nnen. Diese Attribute k√∂nnen gesch√§ftsspezifische Daten, Zwischenberechnungen oder jeden Kontext umfassen, der f√ºr Debugging oder Analyse n√ºtzlich sein k√∂nnte, wie `user_id`, `session_id` oder `model_version`.

Beispiel f√ºr die manuelle Erstellung von Traces und Spans mit dem [Langfuse Python SDK](https://langfuse.com/docs/sdk/python/sdk-v3):

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## Agentenbewertung

Beobachtbarkeit liefert uns Kennzahlen, aber die Bewertung ist der Prozess der Analyse dieser Daten (und der Durchf√ºhrung von Tests), um festzustellen, wie gut ein KI-Agent funktioniert und wie er verbessert werden kann. Mit anderen Worten, sobald du diese Traces und Kennzahlen hast, wie nutzt du sie, um den Agenten zu beurteilen und Entscheidungen zu treffen?

Regelm√§√üige Bewertung ist wichtig, da KI-Agenten oft nicht-deterministisch sind und sich entwickeln k√∂nnen (durch Updates oder driftendes Modellverhalten) ‚Äì ohne Bewertung w√ºsstest du nicht, ob dein "intelligenter Agent" tats√§chlich gut arbeitet oder ob er sich verschlechtert hat.

Es gibt zwei Kategorien von Bewertungen f√ºr KI-Agenten: **Offline-Bewertung** und **Online-Bewertung**. Beide sind wertvoll und erg√§nzen sich gegenseitig. Normalerweise beginnen wir mit der Offline-Bewertung, da dies der Mindestschritt ist, bevor ein Agent bereitgestellt wird.

### Offline-Bewertung

![Datensatz-Elemente in Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

Dies beinhaltet die Bewertung des Agenten in einer kontrollierten Umgebung, typischerweise mit Testdatens√§tzen, nicht mit Live-Benutzeranfragen. Du verwendest kuratierte Datens√§tze, bei denen du wei√üt, was die erwartete Ausgabe oder das korrekte Verhalten ist, und l√§sst deinen Agenten diese ausf√ºhren.

Zum Beispiel, wenn du einen Agenten f√ºr mathematische Textaufgaben erstellt hast, k√∂nntest du einen [Testdatensatz](https://huggingface.co/datasets/gsm8k) mit 100 Aufgaben und bekannten Antworten haben. Die Offline-Bewertung wird oft w√§hrend der Entwicklung durchgef√ºhrt (und kann Teil von CI/CD-Pipelines sein), um Verbesserungen zu √ºberpr√ºfen oder Regressionen zu verhindern. Der Vorteil ist, dass sie **wiederholbar ist und du klare Genauigkeitskennzahlen erh√§ltst, da du eine Ground Truth hast**. Du k√∂nntest auch Benutzeranfragen simulieren und die Antworten des Agenten mit idealen Antworten vergleichen oder automatisierte Kennzahlen wie oben beschrieben verwenden.

Die gr√∂√üte Herausforderung bei der Offline-Bewertung besteht darin, sicherzustellen, dass dein Testdatensatz umfassend und relevant bleibt ‚Äì der Agent k√∂nnte auf einem festen Testsatz gut abschneiden, aber in der Produktion auf sehr unterschiedliche Anfragen sto√üen. Daher solltest du Tests√§tze mit neuen Randf√§llen und Beispielen aktualisieren, die reale Szenarien widerspiegeln. Eine Mischung aus kleinen "Smoke-Test"-F√§llen und gr√∂√üeren Bewertungss√§tzen ist n√ºtzlich: kleine S√§tze f√ºr schnelle √úberpr√ºfungen und gr√∂√üere f√ºr umfassendere Leistungskennzahlen.

### Online-Bewertung

![√úbersicht der Beobachtungskennzahlen](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

Dies bezieht sich auf die Bewertung des Agenten in einer Live-Umgebung, d. h. w√§hrend der tats√§chlichen Nutzung in der Produktion. Die Online-Bewertung umfasst die kontinuierliche √úberwachung der Leistung des Agenten bei realen Benutzerinteraktionen und die Analyse der Ergebnisse.

Zum Beispiel k√∂nntest du Erfolgsraten, Benutzerzufriedenheitsbewertungen oder andere Kennzahlen im Live-Traffic verfolgen. Der Vorteil der Online-Bewertung ist, dass sie **Dinge erfasst, die du in einer Laborumgebung m√∂glicherweise nicht vorhersehen kannst** ‚Äì du kannst Modell-Drift im Laufe der Zeit beobachten (wenn die Effektivit√§t des Agenten nachl√§sst, da sich Eingabemuster √§ndern) und unerwartete Anfragen oder Situationen erkennen, die nicht in deinen Testdaten enthalten waren. Sie bietet ein echtes Bild davon, wie sich der Agent in der Praxis verh√§lt.

Die Online-Bewertung umfasst oft die Sammlung von implizitem und explizitem Benutzerfeedback, wie bereits besprochen, und m√∂glicherweise das Durchf√ºhren von Shadow-Tests oder A/B-Tests (bei denen eine neue Version des Agenten parallel l√§uft, um sie mit der alten zu vergleichen). Die Herausforderung besteht darin, zuverl√§ssige Labels oder Bewertungen f√ºr Live-Interaktionen zu erhalten ‚Äì du k√∂nntest dich auf Benutzerfeedback oder nachgelagerte Kennzahlen verlassen (z. B. ob der Benutzer auf das Ergebnis geklickt hat).

### Kombination der beiden

Online- und Offline-Bewertungen schlie√üen sich nicht gegenseitig aus; sie erg√§nzen sich hervorragend. Erkenntnisse aus der Online-√úberwachung (z. B. neue Arten von Benutzeranfragen, bei denen der Agent schlecht abschneidet) k√∂nnen genutzt werden, um Offline-Testdatens√§tze zu erweitern und zu verbessern. Umgekehrt k√∂nnen Agenten, die in Offline-Tests gut abschneiden, mit gr√∂√üerem Vertrauen bereitgestellt und online √ºberwacht werden.

Tats√§chlich verfolgen viele Teams einen Zyklus:

_offline bewerten -> bereitstellen -> online √ºberwachen -> neue Fehlerf√§lle sammeln -> zum Offline-Datensatz hinzuf√ºgen -> Agenten verfeinern -> wiederholen_.

## H√§ufige Probleme

Bei der Bereitstellung von KI-Agenten in der Produktion k√∂nnen verschiedene Herausforderungen auftreten. Hier sind einige h√§ufige Probleme und m√∂gliche L√∂sungen:

| **Problem**    | **M√∂gliche L√∂sung**   |
| ------------- | ------------------ |
| KI-Agent f√ºhrt Aufgaben nicht konsistent aus | - Verfeinere den Prompt, der dem KI-Agenten gegeben wird; sei klar in den Zielen.<br>- Identifiziere, wo das Aufteilen der Aufgaben in Unteraufgaben und deren Bearbeitung durch mehrere Agenten helfen kann. |
| KI-Agent ger√§t in Endlosschleifen  | - Stelle sicher, dass klare Abbruchbedingungen definiert sind, damit der Agent wei√ü, wann der Prozess beendet werden soll.<br>- F√ºr komplexe Aufgaben, die logisches Denken und Planung erfordern, verwende ein gr√∂√üeres Modell, das auf solche Aufgaben spezialisiert ist. |
| Werkzeugaufrufe des KI-Agenten funktionieren nicht gut   | - Teste und validiere die Ausgabe des Werkzeugs au√üerhalb des Agentensystems. |

- Verfeinern Sie die definierten Parameter, Eingabeaufforderungen und Benennung der Tools.  |
| Multi-Agenten-System funktioniert nicht konsistent | - Verfeinern Sie die Eingabeaufforderungen f√ºr jeden Agenten, um sicherzustellen, dass sie spezifisch und voneinander unterscheidbar sind.<br>- Erstellen Sie ein hierarchisches System mit einem "Routing"- oder Steuerungsagenten, der bestimmt, welcher Agent der richtige ist. |

Viele dieser Probleme k√∂nnen effektiver erkannt werden, wenn eine Beobachtbarkeit implementiert ist. Die zuvor besprochenen Traces und Metriken helfen dabei, genau zu bestimmen, wo im Workflow des Agenten Probleme auftreten, was das Debugging und die Optimierung erheblich effizienter macht.

## Kostenmanagement

Hier sind einige Strategien, um die Kosten f√ºr den Einsatz von KI-Agenten in der Produktion zu verwalten:

**Verwendung kleinerer Modelle:** Kleine Sprachmodelle (Small Language Models, SLMs) k√∂nnen bei bestimmten agentischen Anwendungsf√§llen gut abschneiden und die Kosten erheblich senken. Wie bereits erw√§hnt, ist der Aufbau eines Bewertungssystems, um die Leistung im Vergleich zu gr√∂√üeren Modellen zu bestimmen und zu vergleichen, der beste Weg, um zu verstehen, wie gut ein SLM f√ºr Ihren Anwendungsfall geeignet ist. Ziehen Sie in Betracht, SLMs f√ºr einfachere Aufgaben wie Intent-Klassifikation oder Parameterextraktion zu verwenden, w√§hrend gr√∂√üere Modelle f√ºr komplexes Denken reserviert bleiben.

**Verwendung eines Router-Modells:** Eine √§hnliche Strategie besteht darin, eine Vielfalt von Modellen und Gr√∂√üen zu nutzen. Sie k√∂nnen ein LLM/SLM oder eine serverlose Funktion verwenden, um Anfragen basierend auf ihrer Komplexit√§t an die am besten geeigneten Modelle weiterzuleiten. Dies hilft nicht nur, die Kosten zu senken, sondern stellt auch sicher, dass die Leistung f√ºr die richtigen Aufgaben gew√§hrleistet ist. Beispielsweise k√∂nnen einfache Anfragen an kleinere, schnellere Modelle weitergeleitet werden, w√§hrend teure gro√üe Modelle nur f√ºr komplexe Denkaufgaben verwendet werden.

**Caching von Antworten:** Das Identifizieren h√§ufiger Anfragen und Aufgaben und das Bereitstellen der Antworten, bevor sie durch Ihr agentisches System laufen, ist eine gute M√∂glichkeit, das Volumen √§hnlicher Anfragen zu reduzieren. Sie k√∂nnen sogar einen Ablauf implementieren, um zu erkennen, wie √§hnlich eine Anfrage Ihren gecachten Anfragen ist, indem Sie einfachere KI-Modelle verwenden. Diese Strategie kann die Kosten f√ºr h√§ufig gestellte Fragen oder g√§ngige Workflows erheblich senken.

## Schauen wir uns an, wie das in der Praxis funktioniert

Im [Beispiel-Notebook dieses Abschnitts](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) sehen wir Beispiele daf√ºr, wie wir Beobachtungstools nutzen k√∂nnen, um unseren Agenten zu √ºberwachen und zu bewerten.

## Vorherige Lektion

[Metakognitions-Designmuster](../09-metacognition/README.md)

## N√§chste Lektion

[MCP](../11-mcp/README.md)

**Haftungsausschluss**:  
Dieses Dokument wurde mit dem KI-√úbersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, beachten Sie bitte, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner urspr√ºnglichen Sprache sollte als ma√ügebliche Quelle betrachtet werden. F√ºr kritische Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die sich aus der Nutzung dieser √úbersetzung ergeben.