<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8164484c16b1ed3287ef9dae9fc437c1",
  "translation_date": "2025-07-24T09:05:09+00:00",
  "source_file": "10-ai-agents-production/README.md",
  "language_code": "bg"
}
-->
# AI Агенти в Производство: Наблюдаемост и Оценка

С преминаването на AI агентите от експериментални прототипи към реални приложения, става все по-важно да разбираме тяхното поведение, да следим тяхната производителност и систематично да оценяваме техните резултати.

## Цели на обучението

След завършване на този урок ще знаете как да/разбирате:
- Основни концепции за наблюдаемост и оценка на агентите
- Техники за подобряване на производителността, разходите и ефективността на агентите
- Какво и как да оценявате систематично вашите AI агенти
- Как да контролирате разходите при внедряване на AI агенти в производство
- Как да инструментализирате агенти, създадени с AutoGen

Целта е да ви предоставим знания, които да трансформират вашите "черни кутии" в прозрачни, управляеми и надеждни системи.

_**Забележка:** Важно е да внедрявате AI агенти, които са безопасни и надеждни. Разгледайте урока [Създаване на надеждни AI агенти](./06-building-trustworthy-agents/README.md) за повече информация._

## Трейсове и Спанове

Инструменти за наблюдаемост като [Langfuse](https://langfuse.com/) или [Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry) обикновено представят изпълнението на агентите като трейсове и спанове.

- **Трейс** представлява цялостната задача на агента от начало до край (например обработка на потребителски въпрос).
- **Спанове** са отделните стъпки в рамките на трейса (например извикване на езиков модел или извличане на данни).

![Дърво на трейсове в Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

Без наблюдаемост, AI агентът може да изглежда като "черна кутия" – вътрешното му състояние и логика са непрозрачни, което затруднява диагностицирането на проблеми или оптимизирането на производителността. С наблюдаемост агентите се превръщат в "стъклени кутии", осигурявайки прозрачност, която е жизненоважна за изграждане на доверие и гарантиране, че те работят според очакванията.

## Защо наблюдаемостта е важна в производствени среди

Преминаването на AI агентите към производствени среди въвежда нов набор от предизвикателства и изисквания. Наблюдаемостта вече не е "приятна добавка", а критична способност:

*   **Отстраняване на грешки и анализ на причините:** Когато агентът се провали или произведе неочакван резултат, инструментите за наблюдаемост предоставят трейсовете, необходими за локализиране на източника на грешката. Това е особено важно при сложни агенти, които могат да включват множество извиквания на LLM, взаимодействия с инструменти и условна логика.
*   **Управление на латентност и разходи:** AI агентите често разчитат на LLM и други външни API, които се таксуват на база токени или извиквания. Наблюдаемостта позволява прецизно проследяване на тези извиквания, помагайки да се идентифицират операции, които са прекалено бавни или скъпи. Това позволява на екипите да оптимизират подканите, да изберат по-ефективни модели или да преработят работните потоци, за да управляват оперативните разходи и да осигурят добро потребителско изживяване.
*   **Доверие, безопасност и съответствие:** В много приложения е важно да се гарантира, че агентите се държат безопасно и етично. Наблюдаемостта предоставя одитна следа на действията и решенията на агента. Това може да се използва за откриване и смекчаване на проблеми като инжектиране на подканите, генериране на вредно съдържание или неправилно боравене с лична информация (PII). Например, можете да прегледате трейсовете, за да разберете защо агентът е предоставил определен отговор или е използвал конкретен инструмент.
*   **Цикли за непрекъснато подобрение:** Данните от наблюдаемостта са основата на итеративния процес на разработка. Чрез наблюдение на това как агентите се представят в реалния свят, екипите могат да идентифицират области за подобрение, да събират данни за фина настройка на моделите и да валидират въздействието на промените. Това създава обратна връзка, при която прозренията от производствената среда информират офлайн експериментирането и усъвършенстването, водейки до прогресивно по-добра производителност на агентите.

## Основни метрики за проследяване

За да наблюдавате и разбирате поведението на агентите, трябва да се проследяват различни метрики и сигнали. Въпреки че специфичните метрики могат да варират в зависимост от целта на агента, някои са универсално важни.

Ето някои от най-често срещаните метрики, които инструментите за наблюдаемост следят:

**Латентност:** Колко бързо отговаря агентът? Дългото време за изчакване влияе негативно на потребителското изживяване. Трябва да измервате латентността както за задачите, така и за отделните стъпки, като проследявате изпълнението на агента. Например, агент, който отнема 20 секунди за всички извиквания на модел, може да бъде ускорен чрез използване на по-бърз модел или чрез паралелно изпълнение на извикванията.

**Разходи:** Какви са разходите на изпълнение на агент? AI агентите разчитат на LLM извиквания, които се таксуват на база токени или външни API. Честото използване на инструменти или множество подканящи съобщения може бързо да увеличи разходите. Например, ако агент извиква LLM пет пъти за минимално подобрение на качеството, трябва да оцените дали разходите са оправдани или дали можете да намалите броя на извикванията или да използвате по-евтин модел. Мониторингът в реално време също може да помогне за идентифициране на неочаквани пикове (например, грешки, причиняващи прекомерни API цикли).

**Грешки при заявки:** Колко заявки е провалил агентът? Това може да включва API грешки или неуспешни извиквания на инструменти. За да направите агента си по-устойчив в производствена среда, можете да настроите резервни механизми или повторни опити. Например, ако доставчикът на LLM A не работи, можете да превключите към доставчик B като резервен вариант.

**Обратна връзка от потребители:** Внедряването на директни оценки от потребителите предоставя ценни прозрения. Това може да включва явни оценки (👍положителна/👎отрицателна, ⭐1-5 звезди) или текстови коментари. Постоянната негативна обратна връзка трябва да ви алармира, тъй като това е знак, че агентът не работи според очакванията.

**Непряка обратна връзка от потребители:** Поведението на потребителите предоставя индиректна обратна връзка дори без явни оценки. Това може да включва незабавно преформулиране на въпроси, повтарящи се заявки или натискане на бутон за повторен опит. Например, ако виждате, че потребителите многократно задават един и същ въпрос, това е знак, че агентът не работи според очакванията.

**Точност:** Колко често агентът произвежда правилни или желани резултати? Дефинициите за точност варират (например, коректност при решаване на задачи, точност при извличане на информация, удовлетвореност на потребителите). Първата стъпка е да дефинирате как изглежда успехът за вашия агент. Можете да проследявате точността чрез автоматизирани проверки, оценки или етикети за завършване на задачи. Например, маркиране на трейсове като "успешни" или "неуспешни".

**Автоматизирани метрики за оценка:** Можете също така да настроите автоматизирани оценки. Например, можете да използвате LLM за оценка на изхода на агента, например дали е полезен, точен или не. Съществуват и няколко библиотеки с отворен код, които помагат да се оценяват различни аспекти на агента. Например, [RAGAS](https://docs.ragas.io/) за RAG агенти или [LLM Guard](https://llm-guard.com/) за откриване на вреден език или инжектиране на подканите.

На практика, комбинация от тези метрики осигурява най-добро покритие на здравето на AI агента. В [примерния ноутбук](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) в тази глава ще ви покажем как изглеждат тези метрики в реални примери, но първо ще научим как изглежда типичен работен процес за оценка.

## Инструментализиране на вашия агент

За да събирате данни за трейсове, ще трябва да инструментализирате кода си. Целта е да настроите кода на агента така, че да излъчва трейсове и метрики, които могат да бъдат улавяни, обработвани и визуализирани от платформа за наблюдаемост.

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) се утвърди като индустриален стандарт за наблюдаемост на LLM. Той предоставя набор от API, SDK и инструменти за генериране, събиране и експортиране на телеметрични данни.

Съществуват много библиотеки за инструментализиране, които обгръщат съществуващите рамки за агенти и улесняват експортирането на OpenTelemetry спанове към инструмент за наблюдаемост. Ето пример за инструментализиране на AutoGen агент с библиотеката [OpenLit](https://github.com/openlit/openlit):

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

[Примерният ноутбук](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) в тази глава ще демонстрира как да инструментализирате вашия AutoGen агент.

**Ръчно създаване на спанове:** Докато библиотеките за инструментализиране предоставят добра основа, често има случаи, когато е необходима по-детайлна или персонализирана информация. Можете ръчно да създавате спанове, за да добавите персонализирана логика на приложението. По-важното е, че те могат да обогатят автоматично или ръчно създадените спанове с персонализирани атрибути (известни също като тагове или метаданни). Тези атрибути могат да включват специфични за бизнеса данни, междинни изчисления или всякакъв контекст, който може да бъде полезен за отстраняване на грешки или анализ, като `user_id`, `session_id` или `model_version`.

Пример за ръчно създаване на трейсове и спанове с [Langfuse Python SDK](https://langfuse.com/docs/sdk/python/sdk-v3):

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## Оценка на агента

Наблюдаемостта ни предоставя метрики, но оценката е процесът на анализиране на тези данни (и извършване на тестове), за да се определи колко добре се представя AI агентът и как може да бъде подобрен. С други думи, след като разполагате с тези трейсове и метрики, как ги използвате, за да оцените агента и да вземете решения?

Редовната оценка е важна, защото AI агентите често са недетерминистични и могат да се променят (чрез актуализации или промяна в поведението на модела) – без оценка няма да знаете дали вашият "умен агент" всъщност върши добре работата си или дали е регресирал.

Съществуват две категории оценки за AI агенти: **оценка офлайн** и **оценка онлайн**. И двете са ценни и се допълват взаимно. Обикновено започваме с офлайн оценка, тъй като това е минималната необходима стъпка преди внедряване на агент.

### Офлайн оценка

![Елементи от набор от данни в Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

Това включва оценка на агента в контролирана среда, обикновено с помощта на тестови набори от данни, а не на живи потребителски заявки. Използвате подбрани набори от данни, където знаете какъв е очакваният резултат или правилното поведение, и след това пускате агента върху тях.

Например, ако сте създали агент за решаване на математически задачи, може да имате [тестов набор от данни](https://huggingface.co/datasets/gsm8k) с 100 задачи с известни отговори. Офлайн оценката често се извършва по време на разработката (и може да бъде част от CI/CD процеси), за да се проверят подобренията или да се предотвратят регресии. Предимството е, че тя е **повторяема и можете да получите ясни метрики за точност, тъй като разполагате с истина за сравнение**. Можете също така да симулирате потребителски заявки и да измервате отговорите на агента спрямо идеални отговори или да използвате автоматизирани метрики, както беше описано по-горе.

Основното предизвикателство при офлайн оценката е да се гарантира, че тестовият набор от данни е изчерпателен и остава актуален – агентът може да се представя добре на фиксиран тестов набор, но да срещне много различни заявки в производствена среда. Затова трябва да поддържате тестовите набори актуализирани с нови гранични случаи и примери, които отразяват реални сценарии. Полезно е да имате комбинация от малки "smoke test" случаи и по-големи набори за оценка: малки набори за бързи проверки и по-големи за по-широки метрики за производителност.

### Онлайн оценка

![Преглед на метрики за наблюдаемост](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

Това се отнася до оценка на агента в жива, реална среда, т.е. по време на действителна употреба в производство. Онлайн оценката включва непрекъснато наблюдение на производителността на агента при реални взаимодействия с потребители и анализ на резултатите.

Например, може да проследявате проценти на успех, оценки за удовлетвореност на потребителите или други метрики при жива трафик. Предимството на онлайн оценката е, че тя **улавя неща, които може да не предвидите в лабораторна среда** – можете да наблюдавате промяна в модела с времето (ако ефективността на агента намалява с промяна на входните модели) и да засичате неочаквани заявки или ситуации, които не са били в тестовите ви данни. Тя предоставя истинска картина за това как агентът се държи в реалния свят.

Онлайн оценката често включва събиране на имплицитна и експлицитна обратна връзка от потребителите, както беше обсъдено, и евентуално провеждане на shadow тестове или A/B тестове (където нова версия на агента работи паралелно за сравнение със старата). Предизвикателството е, че може да бъде трудно да се получат надеждни етикети или оценки за живи взаимодействия – може да разчитате на обратна връзка от потребителите или на метрики надолу по веригата (например, дали потребителят е кликнал върху резултата).

### Комбиниране на двете

Офлайн и онлайн оценките не се изключват взаимно; те са силно допълващи се. Прозренията от онлайн наблюдението (например нови типове потребителски заявки, при които агентът се представя слабо) могат да се използват за

- Прецизирайте зададените параметри, подсказки и имената на инструментите.  |
| Мултиагентната система не работи последователно | - Прецизирайте подсказките, дадени на всеки агент, за да гарантирате, че са специфични и различни една от друга.<br>- Изградете йерархична система, използвайки "рутиращ" или контролиращ агент, за да определите кой агент е правилният. |

Много от тези проблеми могат да бъдат идентифицирани по-ефективно, ако има наблюдаемост. Трасетата и метриките, които обсъдихме по-рано, помагат да се установи точно къде в работния процес на агентите възникват проблеми, което прави отстраняването на грешки и оптимизацията много по-ефективни.

## Управление на разходите

Ето някои стратегии за управление на разходите при внедряване на AI агенти в продукция:

**Използване на по-малки модели:** Малките езикови модели (SLMs) могат да се справят добре с определени агентни случаи на употреба и значително да намалят разходите. Както беше споменато по-рано, изграждането на система за оценка, която да определи и сравни производителността спрямо по-големите модели, е най-добрият начин да разберете колко добре SLM ще се справи с вашия случай на употреба. Помислете за използване на SLMs за по-прости задачи като класификация на намерения или извличане на параметри, като запазите по-големите модели за сложни разсъждения.

**Използване на модел за маршрутизация:** Подобна стратегия е да използвате разнообразие от модели и размери. Можете да използвате LLM/SLM или безсървърна функция, за да маршрутизирате заявки въз основа на сложността към най-подходящите модели. Това също ще помогне за намаляване на разходите, като същевременно гарантира производителност за правилните задачи. Например, маршрутизирайте прости запитвания към по-малки, по-бързи модели и използвайте скъпи големи модели само за сложни задачи за разсъждение.

**Кеширане на отговори:** Идентифицирането на често срещани заявки и задачи и предоставянето на отговорите преди да преминат през вашата агентна система е добър начин за намаляване на обема на подобни заявки. Можете дори да внедрите поток за идентифициране на това колко подобна е заявката на вашите кеширани заявки, използвайки по-базови AI модели. Тази стратегия може значително да намали разходите за често задавани въпроси или общи работни процеси.

## Нека видим как това работи на практика

В [примерния ноутбук от този раздел](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) ще видим примери за това как можем да използваме инструменти за наблюдаемост, за да наблюдаваме и оценяваме нашия агент.

## Предишен урок

[Дизайнерски модел за метакогниция](../09-metacognition/README.md)

## Следващ урок

[MCP](../11-mcp/README.md)

**Отказ от отговорност**:  
Този документ е преведен с помощта на AI услуга за превод [Co-op Translator](https://github.com/Azure/co-op-translator). Въпреки че се стремим към точност, моля, имайте предвид, че автоматизираните преводи може да съдържат грешки или неточности. Оригиналният документ на неговия изходен език трябва да се счита за авторитетен източник. За критична информация се препоръчва професионален човешки превод. Ние не носим отговорност за каквито и да е недоразумения или погрешни интерпретации, произтичащи от използването на този превод.