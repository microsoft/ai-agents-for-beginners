<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8164484c16b1ed3287ef9dae9fc437c1",
  "translation_date": "2025-07-24T07:33:47+00:00",
  "source_file": "10-ai-agents-production/README.md",
  "language_code": "es"
}
-->
# Agentes de IA en Producci√≥n: Observabilidad y Evaluaci√≥n

A medida que los agentes de IA pasan de ser prototipos experimentales a aplicaciones del mundo real, se vuelve crucial comprender su comportamiento, monitorear su rendimiento y evaluar sistem√°ticamente sus resultados.

## Objetivos de Aprendizaje

Al completar esta lecci√≥n, sabr√°s c√≥mo/entender√°s:
- Conceptos clave de observabilidad y evaluaci√≥n de agentes
- T√©cnicas para mejorar el rendimiento, los costos y la efectividad de los agentes
- Qu√© y c√≥mo evaluar sistem√°ticamente a tus agentes de IA
- C√≥mo controlar los costos al implementar agentes de IA en producci√≥n
- C√≥mo instrumentar agentes construidos con AutoGen

El objetivo es proporcionarte el conocimiento necesario para transformar tus agentes de "caja negra" en sistemas transparentes, manejables y confiables.

_**Nota:** Es importante implementar agentes de IA que sean seguros y confiables. Consulta tambi√©n la lecci√≥n [Construyendo Agentes de IA Confiables](./06-building-trustworthy-agents/README.md)._

## Trazas y Spans

Las herramientas de observabilidad como [Langfuse](https://langfuse.com/) o [Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry) suelen representar las ejecuciones de los agentes como trazas y spans.

- **Traza** representa una tarea completa del agente de principio a fin (como manejar una consulta de usuario).
- **Spans** son pasos individuales dentro de la traza (como llamar a un modelo de lenguaje o recuperar datos).

![√Årbol de trazas en Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

Sin observabilidad, un agente de IA puede sentirse como una "caja negra": su estado interno y razonamiento son opacos, lo que dificulta diagnosticar problemas u optimizar el rendimiento. Con observabilidad, los agentes se convierten en "cajas de cristal", ofreciendo transparencia que es vital para generar confianza y garantizar que operen como se espera.

## Por qu√© la Observabilidad es Importante en Entornos de Producci√≥n

La transici√≥n de los agentes de IA a entornos de producci√≥n introduce un nuevo conjunto de desaf√≠os y requisitos. La observabilidad deja de ser un "lujo" para convertirse en una capacidad cr√≠tica:

*   **Depuraci√≥n y An√°lisis de Causas Ra√≠z**: Cuando un agente falla o produce un resultado inesperado, las herramientas de observabilidad proporcionan las trazas necesarias para identificar la fuente del error. Esto es especialmente importante en agentes complejos que pueden involucrar m√∫ltiples llamadas a LLM, interacciones con herramientas y l√≥gica condicional.
*   **Gesti√≥n de Latencia y Costos**: Los agentes de IA a menudo dependen de LLMs y otras APIs externas que se facturan por token o por llamada. La observabilidad permite un seguimiento preciso de estas llamadas, ayudando a identificar operaciones excesivamente lentas o costosas. Esto permite a los equipos optimizar prompts, seleccionar modelos m√°s eficientes o redise√±ar flujos de trabajo para gestionar costos operativos y garantizar una buena experiencia de usuario.
*   **Confianza, Seguridad y Cumplimiento**: En muchas aplicaciones, es importante garantizar que los agentes se comporten de manera segura y √©tica. La observabilidad proporciona un registro de auditor√≠a de las acciones y decisiones del agente. Esto puede usarse para detectar y mitigar problemas como inyecciones de prompts, generaci√≥n de contenido da√±ino o manejo indebido de informaci√≥n personal identificable (PII). Por ejemplo, puedes revisar trazas para entender por qu√© un agente dio una respuesta espec√≠fica o utiliz√≥ una herramienta en particular.
*   **Ciclos de Mejora Continua**: Los datos de observabilidad son la base de un proceso de desarrollo iterativo. Al monitorear c√≥mo los agentes se desempe√±an en el mundo real, los equipos pueden identificar √°reas de mejora, recopilar datos para ajustar modelos y validar el impacto de los cambios. Esto crea un ciclo de retroalimentaci√≥n donde los conocimientos de producci√≥n obtenidos de la evaluaci√≥n en l√≠nea informan la experimentaci√≥n y refinamiento fuera de l√≠nea, lo que lleva a un rendimiento progresivamente mejor de los agentes.

## M√©tricas Clave a Monitorear

Para monitorear y comprender el comportamiento de los agentes, se debe rastrear una variedad de m√©tricas y se√±ales. Aunque las m√©tricas espec√≠ficas pueden variar seg√∫n el prop√≥sito del agente, algunas son universalmente importantes.

Aqu√≠ est√°n algunas de las m√©tricas m√°s comunes que las herramientas de observabilidad monitorean:

**Latencia:** ¬øQu√© tan r√°pido responde el agente? Los tiempos de espera prolongados afectan negativamente la experiencia del usuario. Deber√≠as medir la latencia de las tareas y los pasos individuales rastreando las ejecuciones del agente. Por ejemplo, un agente que tarda 20 segundos en todas las llamadas al modelo podr√≠a acelerarse utilizando un modelo m√°s r√°pido o ejecutando las llamadas al modelo en paralelo.

**Costos:** ¬øCu√°l es el costo por ejecuci√≥n del agente? Los agentes de IA dependen de llamadas a LLM facturadas por token o APIs externas. El uso frecuente de herramientas o m√∫ltiples prompts puede aumentar r√°pidamente los costos. Por ejemplo, si un agente llama a un LLM cinco veces para una mejora marginal en la calidad, debes evaluar si el costo est√° justificado o si podr√≠as reducir el n√∫mero de llamadas o usar un modelo m√°s econ√≥mico. El monitoreo en tiempo real tambi√©n puede ayudar a identificar picos inesperados (por ejemplo, errores que causan bucles excesivos de API).

**Errores de Solicitud:** ¬øCu√°ntas solicitudes fall√≥ el agente? Esto puede incluir errores de API o fallos en llamadas a herramientas. Para hacer que tu agente sea m√°s robusto en producci√≥n, puedes configurar alternativas o reintentos. Por ejemplo, si el proveedor de LLM A est√° ca√≠do, cambias al proveedor de LLM B como respaldo.

**Retroalimentaci√≥n del Usuario:** Implementar evaluaciones directas de los usuarios proporciona informaci√≥n valiosa. Esto puede incluir calificaciones expl√≠citas (üëçpulgar arriba/üëéabajo, ‚≠ê1-5 estrellas) o comentarios textuales. La retroalimentaci√≥n negativa constante deber√≠a alertarte, ya que es una se√±al de que el agente no est√° funcionando como se espera.

**Retroalimentaci√≥n Impl√≠cita del Usuario:** Los comportamientos de los usuarios proporcionan retroalimentaci√≥n indirecta incluso sin calificaciones expl√≠citas. Esto puede incluir reformulaciones inmediatas de preguntas, consultas repetidas o hacer clic en un bot√≥n de reintento. Por ejemplo, si ves que los usuarios hacen repetidamente la misma pregunta, esto es una se√±al de que el agente no est√° funcionando como se espera.

**Precisi√≥n:** ¬øCon qu√© frecuencia el agente produce resultados correctos o deseables? Las definiciones de precisi√≥n var√≠an (por ejemplo, correcci√≥n en la resoluci√≥n de problemas, precisi√≥n en la recuperaci√≥n de informaci√≥n, satisfacci√≥n del usuario). El primer paso es definir qu√© significa el √©xito para tu agente. Puedes rastrear la precisi√≥n mediante verificaciones automatizadas, puntuaciones de evaluaci√≥n o etiquetas de finalizaci√≥n de tareas. Por ejemplo, marcar trazas como "exitosas" o "fallidas".

**M√©tricas de Evaluaci√≥n Automatizada:** Tambi√©n puedes configurar evaluaciones automatizadas. Por ejemplo, puedes usar un LLM para puntuar la salida del agente, evaluando si es √∫til, precisa o no. Tambi√©n hay varias bibliotecas de c√≥digo abierto que te ayudan a puntuar diferentes aspectos del agente. Por ejemplo, [RAGAS](https://docs.ragas.io/) para agentes RAG o [LLM Guard](https://llm-guard.com/) para detectar lenguaje da√±ino o inyecciones de prompts.

En la pr√°ctica, una combinaci√≥n de estas m√©tricas ofrece la mejor cobertura de la salud de un agente de IA. En el [notebook de ejemplo](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) de este cap√≠tulo, te mostraremos c√≥mo se ven estas m√©tricas en ejemplos reales, pero primero aprenderemos c√≥mo se ve un flujo de trabajo t√≠pico de evaluaci√≥n.

## Instrumenta tu Agente

Para recopilar datos de trazas, necesitar√°s instrumentar tu c√≥digo. El objetivo es instrumentar el c√≥digo del agente para emitir trazas y m√©tricas que puedan ser capturadas, procesadas y visualizadas por una plataforma de observabilidad.

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) se ha convertido en un est√°ndar de la industria para la observabilidad de LLM. Proporciona un conjunto de APIs, SDKs y herramientas para generar, recopilar y exportar datos de telemetr√≠a.

Existen muchas bibliotecas de instrumentaci√≥n que envuelven marcos de trabajo de agentes existentes y facilitan la exportaci√≥n de spans de OpenTelemetry a una herramienta de observabilidad. A continuaci√≥n, un ejemplo de c√≥mo instrumentar un agente AutoGen con la biblioteca de instrumentaci√≥n [OpenLit](https://github.com/openlit/openlit):

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

El [notebook de ejemplo](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) en este cap√≠tulo demostrar√° c√≥mo instrumentar tu agente AutoGen.

**Creaci√≥n Manual de Spans:** Aunque las bibliotecas de instrumentaci√≥n proporcionan una buena base, a menudo hay casos donde se necesita informaci√≥n m√°s detallada o personalizada. Puedes crear spans manualmente para agregar l√≥gica personalizada de la aplicaci√≥n. M√°s importante a√∫n, puedes enriquecer spans creados autom√°ticamente o manualmente con atributos personalizados (tambi√©n conocidos como etiquetas o metadatos). Estos atributos pueden incluir datos espec√≠ficos del negocio, c√°lculos intermedios o cualquier contexto que pueda ser √∫til para la depuraci√≥n o el an√°lisis, como `user_id`, `session_id` o `model_version`.

Ejemplo de creaci√≥n manual de trazas y spans con el [SDK de Python de Langfuse](https://langfuse.com/docs/sdk/python/sdk-v3):

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## Evaluaci√≥n de Agentes

La observabilidad nos da m√©tricas, pero la evaluaci√≥n es el proceso de analizar esos datos (y realizar pruebas) para determinar qu√© tan bien est√° funcionando un agente de IA y c√≥mo puede mejorarse. En otras palabras, una vez que tienes esas trazas y m√©tricas, ¬øc√≥mo las usas para juzgar al agente y tomar decisiones?

La evaluaci√≥n regular es importante porque los agentes de IA a menudo son no deterministas y pueden evolucionar (a trav√©s de actualizaciones o cambios en el comportamiento del modelo). Sin evaluaci√≥n, no sabr√≠as si tu "agente inteligente" realmente est√° haciendo bien su trabajo o si ha retrocedido.

Hay dos categor√≠as de evaluaciones para agentes de IA: **evaluaci√≥n offline** y **evaluaci√≥n online**. Ambas son valiosas y se complementan entre s√≠. Generalmente comenzamos con la evaluaci√≥n offline, ya que este es el paso m√≠nimo necesario antes de implementar cualquier agente.

### Evaluaci√≥n Offline

![Elementos del dataset en Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

Esto implica evaluar al agente en un entorno controlado, t√≠picamente utilizando conjuntos de datos de prueba, no consultas de usuarios en vivo. Usas conjuntos de datos curados donde sabes cu√°l es el resultado esperado o el comportamiento correcto, y luego ejecutas tu agente en ellos.

Por ejemplo, si construiste un agente para resolver problemas matem√°ticos, podr√≠as tener un [conjunto de datos de prueba](https://huggingface.co/datasets/gsm8k) de 100 problemas con respuestas conocidas. La evaluaci√≥n offline a menudo se realiza durante el desarrollo (y puede formar parte de los pipelines de CI/CD) para verificar mejoras o prevenir regresiones. El beneficio es que es **repetible y puedes obtener m√©tricas claras de precisi√≥n, ya que tienes una verdad base**. Tambi√©n podr√≠as simular consultas de usuarios y medir las respuestas del agente frente a respuestas ideales o usar m√©tricas automatizadas como se describi√≥ anteriormente.

El desaf√≠o clave con la evaluaci√≥n offline es garantizar que tu conjunto de datos de prueba sea completo y se mantenga relevante: el agente podr√≠a desempe√±arse bien en un conjunto de prueba fijo pero enfrentar consultas muy diferentes en producci√≥n. Por lo tanto, deber√≠as mantener los conjuntos de prueba actualizados con nuevos casos l√≠mite y ejemplos que reflejen escenarios del mundo real. Una mezcla de peque√±os casos de "prueba de humo" y conjuntos de evaluaci√≥n m√°s grandes es √∫til: conjuntos peque√±os para verificaciones r√°pidas y conjuntos m√°s grandes para m√©tricas de rendimiento m√°s amplias.

### Evaluaci√≥n Online

![Resumen de m√©tricas de observabilidad](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

Esto se refiere a evaluar al agente en un entorno en vivo, en el mundo real, es decir, durante el uso real en producci√≥n. La evaluaci√≥n online implica monitorear el rendimiento del agente en interacciones reales con usuarios y analizar los resultados de manera continua.

Por ejemplo, podr√≠as rastrear tasas de √©xito, puntuaciones de satisfacci√≥n del usuario u otras m√©tricas en tr√°fico en vivo. La ventaja de la evaluaci√≥n online es que **captura cosas que podr√≠as no anticipar en un entorno de laboratorio**: puedes observar el desv√≠o del modelo con el tiempo (si la efectividad del agente se degrada a medida que cambian los patrones de entrada) y detectar consultas o situaciones inesperadas que no estaban en tus datos de prueba. Proporciona una imagen real de c√≥mo se comporta el agente en el mundo real.

La evaluaci√≥n online a menudo implica recopilar retroalimentaci√≥n impl√≠cita y expl√≠cita de los usuarios, como se discuti√≥, y posiblemente realizar pruebas en sombra o pruebas A/B (donde una nueva versi√≥n del agente se ejecuta en paralelo para compararla con la antigua). El desaf√≠o es que puede ser complicado obtener etiquetas o puntuaciones confiables para interacciones en vivo: podr√≠as depender de la retroalimentaci√≥n del usuario o m√©tricas posteriores (como si el usuario hizo clic en el resultado).

### Combinando ambas

Las evaluaciones online y offline no son mutuamente excluyentes; son altamente complementarias. Los conocimientos obtenidos del monitoreo online (por ejemplo, nuevos tipos de consultas de usuarios donde el agente tiene un mal desempe√±o) pueden usarse para ampliar y mejorar los conjuntos de datos de prueba offline. Por otro lado, los agentes que se desempe√±an bien en pruebas offline pueden implementarse y monitorearse con mayor confianza en l√≠nea.

De hecho, muchos equipos adoptan un ciclo:

_evaluar offline -> implementar -> monitorear online -> recopilar nuevos casos de falla -> agregar al conjunto de datos offline -> refinar el agente -> repetir_.

## Problemas Comunes

Al implementar agentes de IA en producci√≥n, puedes encontrarte con varios desaf√≠os. Aqu√≠ hay algunos problemas comunes y sus posibles soluciones:

| **Problema**    | **Posible Soluci√≥n**   |
| ------------- | ------------------ |
| El agente de IA no realiza tareas de manera consistente | - Refinar el prompt dado al agente de IA; ser claro en los objetivos.<br>- Identificar si dividir las tareas en subtareas y manejarlas con m√∫ltiples agentes puede ayudar. |
| El agente de IA entra en bucles continuos  | - Aseg√∫rate de tener t√©rminos y condiciones claros de finalizaci√≥n para que el agente sepa cu√°ndo detenerse.<br>- Para tareas complejas que requieren razonamiento y planificaci√≥n, utiliza un modelo m√°s grande especializado en tareas de razonamiento. |
| Las llamadas a herramientas del agente de IA no funcionan bien   | - Prueba y valida la salida de la herramienta fuera del sistema del agente. |

- Refina los par√°metros definidos, los prompts y los nombres de las herramientas.  |
| El sistema multiagente no funciona de manera consistente | - Ajusta los prompts dados a cada agente para asegurarte de que sean espec√≠ficos y distintos entre s√≠.<br>- Construye un sistema jer√°rquico utilizando un agente "enrutador" o controlador para determinar cu√°l agente es el adecuado. |

Muchos de estos problemas pueden identificarse de manera m√°s efectiva si se cuenta con herramientas de observabilidad. Los rastreos y m√©tricas que discutimos anteriormente ayudan a localizar exactamente d√≥nde ocurren los problemas en el flujo de trabajo del agente, haciendo que la depuraci√≥n y la optimizaci√≥n sean mucho m√°s eficientes.

## Gesti√≥n de Costos

Aqu√≠ tienes algunas estrategias para gestionar los costos de implementar agentes de IA en producci√≥n:

**Uso de Modelos M√°s Peque√±os:** Los Modelos de Lenguaje Peque√±os (SLMs, por sus siglas en ingl√©s) pueden desempe√±arse bien en ciertos casos de uso de agentes y reducir significativamente los costos. Como se mencion√≥ anteriormente, construir un sistema de evaluaci√≥n para determinar y comparar el rendimiento frente a modelos m√°s grandes es la mejor manera de entender qu√© tan bien un SLM se ajustar√° a tu caso de uso. Considera usar SLMs para tareas m√°s simples como la clasificaci√≥n de intenciones o la extracci√≥n de par√°metros, reservando los modelos m√°s grandes para razonamientos complejos.

**Uso de un Modelo Enrutador:** Una estrategia similar es usar una diversidad de modelos y tama√±os. Puedes usar un LLM/SLM o una funci√≥n sin servidor para enrutar solicitudes seg√∫n su complejidad hacia los modelos m√°s adecuados. Esto tambi√©n ayudar√° a reducir costos mientras se asegura un buen rendimiento en las tareas correctas. Por ejemplo, enruta consultas simples a modelos m√°s peque√±os y r√°pidos, y utiliza modelos grandes y costosos solo para tareas de razonamiento complejo.

**Almacenamiento en Cach√© de Respuestas:** Identificar solicitudes y tareas comunes y proporcionar las respuestas antes de que pasen por tu sistema de agentes es una buena manera de reducir el volumen de solicitudes similares. Incluso puedes implementar un flujo para identificar qu√© tan similar es una solicitud a tus solicitudes en cach√© utilizando modelos de IA m√°s b√°sicos. Esta estrategia puede reducir significativamente los costos para preguntas frecuentes o flujos de trabajo comunes.

## Veamos c√≥mo funciona esto en la pr√°ctica

En el [notebook de ejemplo de esta secci√≥n](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb), veremos ejemplos de c√≥mo podemos usar herramientas de observabilidad para monitorear y evaluar nuestro agente.

## Lecci√≥n Anterior

[Patr√≥n de Dise√±o de Metacognici√≥n](../09-metacognition/README.md)

## Pr√≥xima Lecci√≥n

[MCP](../11-mcp/README.md)

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Si bien nos esforzamos por garantizar la precisi√≥n, tenga en cuenta que las traducciones automatizadas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.