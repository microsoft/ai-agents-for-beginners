<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8164484c16b1ed3287ef9dae9fc437c1",
  "translation_date": "2025-07-24T08:33:26+00:00",
  "source_file": "10-ai-agents-production/README.md",
  "language_code": "no"
}
-->
# AI-agenter i produksjon: Observabilitet og evaluering

N√•r AI-agenter g√•r fra eksperimentelle prototyper til virkelige applikasjoner, blir det viktig √• forst√• deres oppf√∏rsel, overv√•ke ytelsen og systematisk evaluere resultatene.

## L√¶ringsm√•l

Etter √• ha fullf√∏rt denne leksjonen, vil du vite hvordan du/forst√•:
- Grunnleggende konsepter innen observabilitet og evaluering av agenter
- Teknikker for √• forbedre ytelse, kostnader og effektivitet hos agenter
- Hva og hvordan du systematisk evaluerer AI-agentene dine
- Hvordan kontrollere kostnader ved √• sette AI-agenter i produksjon
- Hvordan instrumentere agenter bygget med AutoGen

M√•let er √• gi deg kunnskapen som trengs for √• transformere "svart boks"-agenter til transparente, h√•ndterbare og p√•litelige systemer.

_**Merk:** Det er viktig √• sette ut AI-agenter som er sikre og p√•litelige. Sjekk ut leksjonen [Bygge p√•litelige AI-agenter](./06-building-trustworthy-agents/README.md) ogs√•._

## Traces og spans

Observabilitetsverkt√∏y som [Langfuse](https://langfuse.com/) eller [Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry) representerer vanligvis agentkj√∏ringer som traces og spans.

- **Trace** representerer en komplett agentoppgave fra start til slutt (som √• h√•ndtere en brukerforesp√∏rsel).
- **Spans** er individuelle steg innenfor en trace (som √• kalle en spr√•kmodell eller hente data).

![Trace-tre i Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

Uten observabilitet kan en AI-agent f√∏les som en "svart boks" ‚Äì dens interne tilstand og resonnement er uklare, noe som gj√∏r det vanskelig √• diagnostisere problemer eller optimalisere ytelsen. Med observabilitet blir agenter "glassbokser," som gir den transparensen som er avgj√∏rende for √• bygge tillit og sikre at de fungerer som tiltenkt.

## Hvorfor observabilitet er viktig i produksjonsmilj√∏er

Overgangen til produksjonsmilj√∏er introduserer nye utfordringer og krav. Observabilitet er ikke lenger en "kjekt √• ha"-funksjon, men en kritisk kapasitet:

*   **Feils√∏king og rot√•rsaksanalyse**: N√•r en agent feiler eller gir et uventet resultat, gir observabilitetsverkt√∏y traces som trengs for √• finne kilden til feilen. Dette er spesielt viktig i komplekse agenter som kan involvere flere LLM-kall, verkt√∏yinteraksjoner og betinget logikk.
*   **Latens- og kostnadsstyring**: AI-agenter er ofte avhengige av LLM-er og andre eksterne API-er som faktureres per token eller per kall. Observabilitet muliggj√∏r presis sporing av disse kallene, noe som hjelper med √• identifisere operasjoner som er un√∏dvendig trege eller dyre. Dette gj√∏r det mulig for team √• optimalisere prompts, velge mer effektive modeller eller redesigne arbeidsflyter for √• h√•ndtere driftskostnader og sikre en god brukeropplevelse.
*   **Tillit, sikkerhet og samsvar**: I mange applikasjoner er det viktig √• sikre at agenter oppf√∏rer seg trygt og etisk. Observabilitet gir en revisjonsspor av agentens handlinger og beslutninger. Dette kan brukes til √• oppdage og h√•ndtere problemer som prompt-injeksjon, generering av skadelig innhold eller feilbehandling av personlig identifiserbar informasjon (PII). For eksempel kan du gjennomg√• traces for √• forst√• hvorfor en agent ga et bestemt svar eller brukte et spesifikt verkt√∏y.
*   **Kontinuerlige forbedringssl√∏yfer**: Observabilitetsdata er grunnlaget for en iterativ utviklingsprosess. Ved √• overv√•ke hvordan agenter presterer i den virkelige verden, kan team identifisere forbedringsomr√•der, samle data for finjustering av modeller og validere effekten av endringer. Dette skaper en tilbakemeldingssl√∏yfe der produksjonsinnsikt fra online evaluering informerer offline eksperimentering og raffinering, noe som f√∏rer til gradvis bedre agentytelse.

## Viktige metrikker √• spore

For √• overv√•ke og forst√• agentens oppf√∏rsel, b√∏r en rekke metrikker og signaler spores. Selv om de spesifikke metrikker kan variere basert p√• agentens form√•l, er noen universelt viktige.

Her er noen av de vanligste metrikker som observabilitetsverkt√∏y overv√•ker:

**Latens:** Hvor raskt svarer agenten? Lange ventetider p√•virker brukeropplevelsen negativt. Du b√∏r m√•le latens for oppgaver og individuelle steg ved √• spore agentkj√∏ringer. For eksempel kan en agent som bruker 20 sekunder p√• alle modellkall akselereres ved √• bruke en raskere modell eller ved √• kj√∏re modellkall parallelt.

**Kostnader:** Hva er kostnaden per agentkj√∏ring? AI-agenter er avhengige av LLM-kall som faktureres per token eller eksterne API-er. Hyppig verkt√∏ybruk eller flere prompts kan raskt √∏ke kostnadene. For eksempel, hvis en agent kaller en LLM fem ganger for marginal kvalitetsforbedring, m√• du vurdere om kostnaden er berettiget eller om du kan redusere antall kall eller bruke en billigere modell. Sanntidsoverv√•king kan ogs√• hjelpe med √• identifisere uventede topper (f.eks. feil som for√•rsaker overdrevne API-l√∏kker).

**Foresp√∏rselsfeil:** Hvor mange foresp√∏rsler feilet agenten? Dette kan inkludere API-feil eller mislykkede verkt√∏ykall. For √• gj√∏re agenten mer robust i produksjon, kan du sette opp fallbacks eller retries. F.eks. hvis LLM-leverand√∏r A er nede, kan du bytte til LLM-leverand√∏r B som backup.

**Brukerfeedback:** Implementering av direkte bruker-evalueringer gir verdifull innsikt. Dette kan inkludere eksplisitte vurderinger (üëçtommel opp/üëéned, ‚≠ê1-5 stjerner) eller tekstlige kommentarer. Konsistent negativ feedback b√∏r varsle deg, da dette er et tegn p√• at agenten ikke fungerer som forventet.

**Implisitt brukerfeedback:** Brukeratferd gir indirekte tilbakemeldinger selv uten eksplisitte vurderinger. Dette kan inkludere umiddelbar omformulering av sp√∏rsm√•l, gjentatte foresp√∏rsler eller klikk p√• en "pr√∏v igjen"-knapp. F.eks. hvis du ser at brukere gjentatte ganger stiller det samme sp√∏rsm√•let, er dette et tegn p√• at agenten ikke fungerer som forventet.

**N√∏yaktighet:** Hvor ofte produserer agenten korrekte eller √∏nskelige resultater? Definisjoner av n√∏yaktighet varierer (f.eks. korrekthet i probleml√∏sning, n√∏yaktighet i informasjonsinnhenting, brukertilfredshet). Det f√∏rste steget er √• definere hva suksess betyr for agenten din. Du kan spore n√∏yaktighet via automatiske kontroller, evalueringspoeng eller oppgavefullf√∏ringsetiketter. For eksempel kan du merke traces som "lyktes" eller "feilet".

**Automatiserte evalueringsmetrikker:** Du kan ogs√• sette opp automatiserte evalueringer. For eksempel kan du bruke en LLM til √• score agentens output, f.eks. om det er nyttig, n√∏yaktig eller ikke. Det finnes ogs√• flere √•pne kildebiblioteker som hjelper deg med √• score ulike aspekter av agenten. F.eks. [RAGAS](https://docs.ragas.io/) for RAG-agenter eller [LLM Guard](https://llm-guard.com/) for √• oppdage skadelig spr√•k eller prompt-injeksjon.

I praksis gir en kombinasjon av disse metrikker den beste dekningen av en AI-agents helse. I dette kapitlets [eksempelfil](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) vil vi vise hvordan disse metrikker ser ut i virkelige eksempler, men f√∏rst skal vi l√¶re hvordan en typisk evalueringsarbeidsflyt ser ut.

## Instrumentering av agenten din

For √• samle sporingsdata m√• du instrumentere koden din. M√•let er √• instrumentere agentkoden slik at den sender ut traces og metrikker som kan fanges opp, behandles og visualiseres av en observabilitetsplattform.

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) har blitt en industristandard for observabilitet av LLM-er. Det gir et sett med API-er, SDK-er og verkt√∏y for generering, innsamling og eksport av telemetridata.

Det finnes mange instrumenteringsbiblioteker som pakker inn eksisterende agentrammeverk og gj√∏r det enkelt √• eksportere OpenTelemetry-spans til et observabilitetsverkt√∏y. Nedenfor er et eksempel p√• instrumentering av en AutoGen-agent med [OpenLit-instrumenteringsbiblioteket](https://github.com/openlit/openlit):

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

[Eksempelfilen](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) i dette kapitlet vil demonstrere hvordan du instrumenterer AutoGen-agenten din.

**Manuell opprettelse av spans:** Selv om instrumenteringsbiblioteker gir et godt grunnlag, er det ofte tilfeller der mer detaljert eller tilpasset informasjon er n√∏dvendig. Du kan manuelt opprette spans for √• legge til tilpasset applikasjonslogikk. Enda viktigere, de kan berike automatisk eller manuelt opprettede spans med tilpassede attributter (ogs√• kjent som tags eller metadata). Disse attributtene kan inkludere forretningsspesifikke data, mellomliggende beregninger eller annen kontekst som kan v√¶re nyttig for feils√∏king eller analyse, som `user_id`, `session_id` eller `model_version`.

Eksempel p√• manuell opprettelse av traces og spans med [Langfuse Python SDK](https://langfuse.com/docs/sdk/python/sdk-v3):

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## Evaluering av agenter

Observabilitet gir oss metrikker, men evaluering er prosessen med √• analysere disse dataene (og utf√∏re tester) for √• avgj√∏re hvor godt en AI-agent presterer og hvordan den kan forbedres. Med andre ord, n√•r du har disse traces og metrikker, hvordan bruker du dem til √• vurdere agenten og ta beslutninger?

Regelmessig evaluering er viktig fordi AI-agenter ofte er ikke-deterministiske og kan utvikle seg (gjennom oppdateringer eller endringer i modellens oppf√∏rsel) ‚Äì uten evaluering ville du ikke vite om din "smarte agent" faktisk gj√∏r jobben sin godt eller om den har blitt d√•rligere.

Det finnes to kategorier av evalueringer for AI-agenter: **online evaluering** og **offline evaluering**. Begge er verdifulle, og de utfyller hverandre. Vi begynner vanligvis med offline evaluering, da dette er det minimum n√∏dvendige steget f√∏r man setter ut en agent.

### Offline evaluering

![Datasett-elementer i Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

Dette inneb√¶rer √• evaluere agenten i et kontrollert milj√∏, vanligvis ved bruk av testdatasett, ikke live brukerforesp√∏rsler. Du bruker kuraterte datasett der du vet hva det forventede resultatet eller korrekt oppf√∏rsel er, og deretter kj√∏rer agenten p√• disse.

For eksempel, hvis du har bygget en agent for matematiske tekstoppgaver, kan du ha et [testdatasett](https://huggingface.co/datasets/gsm8k) med 100 oppgaver med kjente svar. Offline evaluering gj√∏res ofte under utvikling (og kan v√¶re en del av CI/CD-pipelines) for √• sjekke forbedringer eller beskytte mot regresjoner. Fordelen er at det er **repeterbart, og du kan f√• klare n√∏yaktighetsmetrikker siden du har fasit**. Du kan ogs√• simulere brukerforesp√∏rsler og m√•le agentens svar mot ideelle svar eller bruke automatiserte metrikker som beskrevet ovenfor.

Den st√∏rste utfordringen med offline evaluering er √• sikre at testdatasettet er omfattende og forblir relevant ‚Äì agenten kan prestere godt p√• et fast testsett, men m√∏te helt andre foresp√∏rsler i produksjon. Derfor b√∏r du holde testsettet oppdatert med nye edge cases og eksempler som reflekterer virkelige scenarier‚Äã. En blanding av sm√• "r√∏yktest"-caser og st√∏rre evalueringssett er nyttig: sm√• sett for raske kontroller og st√∏rre sett for bredere ytelsesm√•linger‚Äã.

### Online evaluering

![Oversikt over observabilitetsmetrikker](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

Dette refererer til evaluering av agenten i et live, virkelighetsn√¶rt milj√∏, alts√• under faktisk bruk i produksjon. Online evaluering inneb√¶rer √• overv√•ke agentens ytelse p√• ekte brukerinteraksjoner og kontinuerlig analysere resultatene.

For eksempel kan du spore suksessrater, brukertilfredshetsscore eller andre metrikker p√• live trafikk. Fordelen med online evaluering er at det **fanger opp ting du kanskje ikke foruts√• i et laboratoriemilj√∏** ‚Äì du kan observere modellens endringer over tid (hvis agentens effektivitet svekkes n√•r inputm√∏nstre endres) og oppdage uventede foresp√∏rsler eller situasjoner som ikke var i testdataene‚Äã. Det gir et sant bilde av hvordan agenten oppf√∏rer seg i praksis.

Online evaluering inneb√¶rer ofte innsamling av implisitt og eksplisitt brukerfeedback, som diskutert, og muligens kj√∏ring av skyggetester eller A/B-tester (der en ny versjon av agenten kj√∏rer parallelt for √• sammenligne med den gamle). Utfordringen er at det kan v√¶re vanskelig √• f√• p√•litelige etiketter eller score for live interaksjoner ‚Äì du kan v√¶re avhengig av brukerfeedback eller nedstr√∏msmetrikker (som om brukeren klikket p√• resultatet).

### Kombinere de to

Online og offline evalueringer er ikke gjensidig utelukkende; de utfyller hverandre sterkt. Innsikt fra online overv√•king (f.eks. nye typer brukerforesp√∏rsler der agenten presterer d√•rlig) kan brukes til √• utvide og forbedre offline testdatasett. P√• samme m√•te kan agenter som presterer godt i offline tester mer trygt settes ut og overv√•kes online.

Faktisk adopterer mange team en sl√∏yfe:

_evaluere offline -> sette ut -> overv√•ke online -> samle nye feiltilfeller -> legge til offline datasett -> forbedre agent -> gjenta_.

## Vanlige problemer

N√•r du setter AI-agenter i produksjon, kan du m√∏te ulike utfordringer. Her er noen vanlige problemer og deres potensielle l√∏sninger:

| **Problem**    | **Potensiell l√∏sning**   |
| ------------- | ------------------ |
| AI-agent utf√∏rer ikke oppgaver konsekvent | - Forbedre prompten som gis til AI-agenten; v√¶r tydelig p√• m√•lene.<br>- Identifiser hvor det kan hjelpe √• dele opp oppgavene i deloppgaver og h√•ndtere dem med flere agenter. |
| AI-agent havner i kontinuerlige l√∏kker  | - S√∏rg for at du har klare avslutningsvilk√•r slik at agenten vet n√•r den skal stoppe prosessen.<br>- For komplekse oppgaver som krever resonnement og planlegging, bruk en st√∏rre modell som er spesialisert for resonnement. |
| AI-agentens verkt√∏ykall fungerer ikke godt   | - Test og valider verkt√∏yets output utenfor agentsystemet.

- Forbedre de definerte parameterne, promptene og navngivningen av verkt√∏y.  |
| Multi-agent-system som ikke presterer konsekvent | - Forbedre promptene som gis til hver agent for √• sikre at de er spesifikke og tydelig adskilt fra hverandre.<br>- Bygg et hierarkisk system ved √• bruke en "rute"- eller kontrollagent for √• avgj√∏re hvilken agent som er den riktige. |

Mange av disse problemene kan identifiseres mer effektivt med observabilitet p√• plass. Sporene og m√•ledataene vi diskuterte tidligere hjelper med √• finne n√∏yaktig hvor i agentens arbeidsflyt problemene oppst√•r, noe som gj√∏r feils√∏king og optimalisering langt mer effektivt.

## H√•ndtering av kostnader

Her er noen strategier for √• h√•ndtere kostnadene ved √• sette AI-agenter i produksjon:

**Bruke mindre modeller:** Sm√• spr√•kmodeller (SLM-er) kan fungere godt for visse agentbaserte bruksomr√•der og vil redusere kostnadene betydelig. Som nevnt tidligere, er det beste m√•ten √• forst√• hvor godt en SLM vil prestere for ditt bruksomr√•de √• bygge et evalueringssystem for √• bestemme og sammenligne ytelsen mot st√∏rre modeller. Vurder √• bruke SLM-er for enklere oppgaver som intensjonsklassifisering eller parameteruttrekk, mens st√∏rre modeller reserveres for komplekse resonneringsoppgaver.

**Bruke en ruter-modell:** En lignende strategi er √• bruke en variasjon av modeller og st√∏rrelser. Du kan bruke en LLM/SLM eller serverl√∏se funksjoner for √• rute foresp√∏rsler basert p√• kompleksitet til de modellene som passer best. Dette vil ogs√• bidra til √• redusere kostnader samtidig som det sikrer ytelse p√• de riktige oppgavene. For eksempel kan enkle foresp√∏rsler rutes til mindre, raskere modeller, mens dyre, store modeller kun brukes til komplekse resonneringsoppgaver.

**Bufring av svar:** Identifisere vanlige foresp√∏rsler og oppgaver og gi svarene f√∏r de g√•r gjennom ditt agentbaserte system er en god m√•te √• redusere volumet av lignende foresp√∏rsler. Du kan til og med implementere en prosess for √• identifisere hvor lik en foresp√∏rsel er med dine bufrede foresp√∏rsler ved hjelp av enklere AI-modeller. Denne strategien kan redusere kostnadene betydelig for ofte stilte sp√∏rsm√•l eller vanlige arbeidsflyter.

## La oss se hvordan dette fungerer i praksis

I [eksempelfilen til denne delen](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) vil vi se eksempler p√• hvordan vi kan bruke observasjonsverkt√∏y for √• overv√•ke og evaluere agenten v√•r.

## Forrige leksjon

[Metakognitivt designm√∏nster](../09-metacognition/README.md)

## Neste leksjon

[MCP](../11-mcp/README.md)

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi tilstreber n√∏yaktighet, vennligst v√¶r oppmerksom p√• at automatiske oversettelser kan inneholde feil eller un√∏yaktigheter. Det originale dokumentet p√• sitt opprinnelige spr√•k b√∏r anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforst√•elser eller feiltolkninger som oppst√•r ved bruk av denne oversettelsen.